{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.image as mpimg # mpimg 用于读取图片\n",
    "\n",
    "data_path = '../data'\n",
    "\n",
    "# 图片的路径，1中包括了数字1-9，0中全部为0\n",
    "path_1 = os.listdir(os.path.join(data_path, '1'))\n",
    "np.random.shuffle(path_1)\n",
    "path_1 = list(map(lambda x: os.path.join(data_path, '1', x), path_1))\n",
    "path_0 = os.listdir(os.path.join(data_path, '0'))\n",
    "path_0 = list(map(lambda x: os.path.join(data_path, '0', x), path_0))\n",
    "\n",
    "\n",
    "def parse_image(image_path):\n",
    "    \"\"\"对所给的图像进行处理，变成一维向量, 并且归一化\n",
    "    Args:\n",
    "        image_path: 图像的路径\n",
    "    Returns：\n",
    "        img: 处理好的图像\n",
    "    \"\"\"\n",
    "    t = mpimg.imread(image_path)\n",
    "    return np.reshape(t, (28 * 28)) / 255.\n",
    "\n",
    "\n",
    "def get_label(paths, labels):\n",
    "    \"\"\"根据给的路径对图像进行处理，打上标签\n",
    "    Args:\n",
    "        paths: 图片路径\n",
    "        labels: 图片标签\n",
    "    Returns:\n",
    "        x: 处理好的图片\n",
    "        y: 对应长度的标签\n",
    "    \"\"\"\n",
    "    x = list(map(parse_image, paths))\n",
    "    if labels == 1:\n",
    "        y = [[1,0] for _ in range(len(paths))]\n",
    "    else:\n",
    "        y = [[0,1] for _ in range(len(paths))]\n",
    "    return x, y\n",
    "\n",
    "\n",
    "data_0 = get_label(path_0, 1)\n",
    "print(data_0[1][:10])\n",
    "\n",
    "\n",
    "data_1 = get_label(path_1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输入图片\n",
    "data_X_train = np.concatenate((data_0[0][:-500], data_1[0][:-500]))\n",
    "# 输入标签数据\n",
    "data_Y_train = np.concatenate((data_0[1][:-500], data_1[1][:-500]))\n",
    "training_set = np.concatenate([data_X_train, data_Y_train], axis=1)\n",
    "# 验证集\n",
    "data_X_test = np.concatenate((data_0[0][-500:], data_1[0][-500:]))\n",
    "data_Y_test = np.concatenate((data_0[1][-500:], data_1[1][-500:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_batch(dataset, batchsize):\n",
    "    \"\"\"根据设定的batchsize大小产生mini batch\n",
    "    Args:\n",
    "        dataset: 数据集\n",
    "        batchsize: batchsize\n",
    "    Generates:\n",
    "        x: 输入\n",
    "        y：输出\n",
    "    \"\"\"\n",
    "    for i in range(np.shape(dataset)[0] // batchsize):\n",
    "        pos = i * batchsize\n",
    "        x = dataset[pos:pos + batchsize, 0:-2]\n",
    "        y = dataset[pos:pos + batchsize, -2:]\n",
    "        yield x, y\n",
    "    remain = np.shape(dataset)[0] % batchsize\n",
    "    if remain != 0:\n",
    "        x, y = dataset[-remain:, 0:-2], dataset[-remain:, -2:]\n",
    "        yield x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize = 64\n",
    "lr = 0.01\n",
    "epoch = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义计算图\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    # 定义placeholder\n",
    "    X = tf.placeholder(shape=(None, 28*28), dtype=tf.float32, name=\"X\")\n",
    "    Y = tf.placeholder(shape=(None, 2), dtype=tf.float32, name=\"Y\")\n",
    "\n",
    "    # 定义weight matrix\n",
    "    W = tf.Variable(tf.truncated_normal(shape=[784, 2]), name=\"WeightMatrix\")\n",
    "    lgt = tf.matmul(X, W)\n",
    "    output = tf.nn.sigmoid(lgt, name=\"Apply_Sigmoid\")\n",
    "    # 定义loss\n",
    "    loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=Y, logits=lgt), name=\"calculate_loss\")\n",
    "    \n",
    "    with tf.name_scope(\"SGD\"):\n",
    "        # 使用梯度下降进行优化\n",
    "        opt = tf.train.GradientDescentOptimizer(lr).minimize(loss, var_list=[W])\n",
    "    \n",
    "    # 计算错误率\n",
    "    with tf.name_scope(\"calculate_error_rate\"):\n",
    "        # 概率大于 0.5 预测结果为0， 否则为 0\n",
    "        pred = tf.argmax(output, axis=1)\n",
    "        true = tf.argmax(Y, axis=1)\n",
    "        accuracy = tf.reduce_mean(tf.cast(tf.equal(pred, true), tf.float32))\n",
    "    \n",
    "\n",
    "        \n",
    "\n",
    "        error_rate = 1 - accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session(graph=graph) as sess:\n",
    "    # 初始化变量\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    step = 0\n",
    "    for epc in range(epoch):\n",
    "        for x, y in gen_batch(training_set, batchsize):\n",
    "            l, error, _ = sess.run([loss, error_rate, opt], feed_dict={X: np.reshape(x, (-1, 784)), Y: np.reshape(y, (-1, 2))})\n",
    "            if step % 50 == 0:\n",
    "                print(\"Step: {:>4}, Loss: {:.4f}, Error Rate: {:.4%}\".format(step, l, error))\n",
    "            step += 1\n",
    "    print(\"Training finished.\")\n",
    "    l, error, weight_matrix = sess.run([loss, error_rate, W],\n",
    "                                       {X: data_X_test, Y: data_Y_test})\n",
    "    print(\"Testing Loss: {:.4f}, Testing Error Rate: {:.4%}\".format(l, error))\n",
    "    W_value = sess.run(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
