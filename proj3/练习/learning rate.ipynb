{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liuyanfang/anaconda3/envs/tensorflow1.4/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting ../MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ../MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('../MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer1 = tf.layers.dense(inputs=x, \n",
    "                         units=20, \n",
    "                         activation=tf.nn.relu,                        \n",
    "                         bias_initializer=tf.constant_initializer(0),\n",
    "                         kernel_initializer=tf.truncated_normal_initializer(stddev=0.1)\n",
    "                        )\n",
    "layer2 = tf.layers.dense(inputs=layer1, \n",
    "                         units=20, \n",
    "                         activation=tf.nn.relu,                        \n",
    "                         bias_initializer=tf.constant_initializer(0),\n",
    "                         kernel_initializer=tf.truncated_normal_initializer(stddev=0.1)\n",
    "                        )\n",
    "layer3 = tf.layers.dense(inputs=layer2, \n",
    "                         units=20, \n",
    "                         activation=tf.nn.relu,                        \n",
    "                         bias_initializer=tf.constant_initializer(0),\n",
    "                         kernel_initializer=tf.truncated_normal_initializer(stddev=0.1)\n",
    "                        )\n",
    "layer4 = tf.layers.dense(inputs=layer3, \n",
    "                         units=20, \n",
    "                         activation=tf.nn.relu,                        \n",
    "                         bias_initializer=tf.constant_initializer(0),\n",
    "                         kernel_initializer=tf.truncated_normal_initializer(stddev=0.1)\n",
    "                        )\n",
    "layer5 = tf.layers.dense(inputs=layer4, \n",
    "                         units=20, \n",
    "                         activation=tf.nn.relu,                        \n",
    "                         bias_initializer=tf.constant_initializer(0),\n",
    "                         kernel_initializer=tf.truncated_normal_initializer(stddev=0.1)\n",
    "                        )\n",
    "layer6 = tf.layers.dense(inputs=layer5, \n",
    "                         units=20, \n",
    "                         activation=tf.nn.relu,                        \n",
    "                         bias_initializer=tf.constant_initializer(0),\n",
    "                         kernel_initializer=tf.truncated_normal_initializer(stddev=0.1)\n",
    "                        )\n",
    "y = tf.layers.dense(inputs=layer6, \n",
    "                    units=10, \n",
    "                    activation=None, \n",
    "                    bias_initializer=tf.constant_initializer(0), \n",
    "                    kernel_initializer=tf.truncated_normal_initializer(stddev=0.1)\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.train.exponential_decay()学习率更改函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "global_steps = tf.Variable(0, trainable=False)  \n",
    "learning_rate = 0.5\n",
    "#learning_rate = tf.train.exponential_decay(0.5, global_steps, 1000, 0.5, staircase=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "softmax_result = tf.nn.softmax(y)\n",
    "pred = tf.argmax(softmax_result, axis=1)\n",
    "true = tf.argmax(y_, axis=1)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(pred, true), tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:    0, Learning_rate:  0.5, Loss: 2.3027, Accuracy:  9.38%\n",
      "Step:  100, Learning_rate:  0.5, Loss: 2.3195, Accuracy:  7.03%\n",
      "Step:  200, Learning_rate:  0.5, Loss: 2.3039, Accuracy:  9.38%\n",
      "Step:  300, Learning_rate:  0.5, Loss: 2.0812, Accuracy: 23.44%\n",
      "Step:  400, Learning_rate:  0.5, Loss: 1.6086, Accuracy: 42.19%\n",
      "Step:  500, Learning_rate:  0.5, Loss: 1.4557, Accuracy: 46.88%\n",
      "Step:  600, Learning_rate:  0.5, Loss: 1.3582, Accuracy: 40.62%\n",
      "Step:  700, Learning_rate:  0.5, Loss: 1.0865, Accuracy: 60.16%\n",
      "Step:  800, Learning_rate:  0.5, Loss: 0.7983, Accuracy: 77.34%\n",
      "Step:  900, Learning_rate:  0.5, Loss: 0.6957, Accuracy: 75.00%\n",
      "Step: 1000, Learning_rate: 0.25, Loss: 0.5105, Accuracy: 80.47%\n",
      "Step: 1100, Learning_rate: 0.25, Loss: 0.2761, Accuracy: 92.97%\n",
      "Step: 1200, Learning_rate: 0.25, Loss: 0.2755, Accuracy: 92.97%\n",
      "Step: 1300, Learning_rate: 0.25, Loss: 0.2697, Accuracy: 95.31%\n",
      "Step: 1400, Learning_rate: 0.25, Loss: 0.2329, Accuracy: 93.75%\n",
      "Step: 1500, Learning_rate: 0.25, Loss: 0.2703, Accuracy: 94.53%\n",
      "Step: 1600, Learning_rate: 0.25, Loss: 0.3881, Accuracy: 89.84%\n",
      "Step: 1700, Learning_rate: 0.25, Loss: 0.4123, Accuracy: 85.94%\n",
      "Step: 1800, Learning_rate: 0.25, Loss: 0.2343, Accuracy: 91.41%\n",
      "Step: 1900, Learning_rate: 0.25, Loss: 0.2365, Accuracy: 92.97%\n",
      "Step: 2000, Learning_rate:0.125, Loss: 0.2588, Accuracy: 92.19%\n",
      "Step: 2100, Learning_rate:0.125, Loss: 0.2848, Accuracy: 92.19%\n",
      "Step: 2200, Learning_rate:0.125, Loss: 0.2796, Accuracy: 91.41%\n",
      "Step: 2300, Learning_rate:0.125, Loss: 0.1793, Accuracy: 94.53%\n",
      "Step: 2400, Learning_rate:0.125, Loss: 0.1242, Accuracy: 96.09%\n",
      "Step: 2500, Learning_rate:0.125, Loss: 0.0921, Accuracy: 96.88%\n",
      "Step: 2600, Learning_rate:0.125, Loss: 0.1905, Accuracy: 94.53%\n",
      "Step: 2700, Learning_rate:0.125, Loss: 0.2874, Accuracy: 94.53%\n",
      "Step: 2800, Learning_rate:0.125, Loss: 0.1562, Accuracy: 96.09%\n",
      "Step: 2900, Learning_rate:0.125, Loss: 0.1333, Accuracy: 96.09%\n",
      "Step: 3000, Learning_rate:0.0625, Loss: 0.2144, Accuracy: 92.97%\n",
      "Step: 3100, Learning_rate:0.0625, Loss: 0.1291, Accuracy: 96.09%\n",
      "Step: 3200, Learning_rate:0.0625, Loss: 0.1190, Accuracy: 96.09%\n",
      "Step: 3300, Learning_rate:0.0625, Loss: 0.1529, Accuracy: 96.09%\n",
      "Step: 3400, Learning_rate:0.0625, Loss: 0.1820, Accuracy: 93.75%\n",
      "Step: 3500, Learning_rate:0.0625, Loss: 0.0506, Accuracy: 99.22%\n",
      "Step: 3600, Learning_rate:0.0625, Loss: 0.1627, Accuracy: 94.53%\n",
      "Step: 3700, Learning_rate:0.0625, Loss: 0.1958, Accuracy: 93.75%\n",
      "Step: 3800, Learning_rate:0.0625, Loss: 0.1697, Accuracy: 96.09%\n",
      "Step: 3900, Learning_rate:0.0625, Loss: 0.1585, Accuracy: 95.31%\n",
      "Step: 4000, Learning_rate:0.03125, Loss: 0.1576, Accuracy: 96.09%\n",
      "Step: 4100, Learning_rate:0.03125, Loss: 0.3028, Accuracy: 89.84%\n",
      "Step: 4200, Learning_rate:0.03125, Loss: 0.2338, Accuracy: 91.41%\n",
      "Step: 4300, Learning_rate:0.03125, Loss: 0.0623, Accuracy: 98.44%\n",
      "Step: 4400, Learning_rate:0.03125, Loss: 0.1460, Accuracy: 95.31%\n",
      "Step: 4500, Learning_rate:0.03125, Loss: 0.1762, Accuracy: 94.53%\n",
      "Step: 4600, Learning_rate:0.03125, Loss: 0.3085, Accuracy: 89.84%\n",
      "Step: 4700, Learning_rate:0.03125, Loss: 0.1185, Accuracy: 96.09%\n",
      "Step: 4800, Learning_rate:0.03125, Loss: 0.1788, Accuracy: 92.97%\n",
      "Step: 4900, Learning_rate:0.03125, Loss: 0.0754, Accuracy: 96.88%\n",
      "Step: 5000, Learning_rate:0.015625, Loss: 0.2582, Accuracy: 94.53%\n",
      "Step: 5100, Learning_rate:0.015625, Loss: 0.2615, Accuracy: 95.31%\n",
      "Step: 5200, Learning_rate:0.015625, Loss: 0.2113, Accuracy: 92.19%\n",
      "Step: 5300, Learning_rate:0.015625, Loss: 0.0687, Accuracy: 98.44%\n",
      "Step: 5400, Learning_rate:0.015625, Loss: 0.2767, Accuracy: 92.19%\n",
      "Step: 5500, Learning_rate:0.015625, Loss: 0.0422, Accuracy:100.00%\n",
      "Step: 5600, Learning_rate:0.015625, Loss: 0.2725, Accuracy: 93.75%\n",
      "Step: 5700, Learning_rate:0.015625, Loss: 0.1549, Accuracy: 96.88%\n",
      "Step: 5800, Learning_rate:0.015625, Loss: 0.0807, Accuracy: 96.88%\n",
      "Step: 5900, Learning_rate:0.015625, Loss: 0.0821, Accuracy: 97.66%\n",
      "Step: 6000, Learning_rate:0.0078125, Loss: 0.1866, Accuracy: 95.31%\n",
      "Step: 6100, Learning_rate:0.0078125, Loss: 0.0543, Accuracy: 98.44%\n",
      "Step: 6200, Learning_rate:0.0078125, Loss: 0.2711, Accuracy: 90.62%\n",
      "Step: 6300, Learning_rate:0.0078125, Loss: 0.1413, Accuracy: 96.09%\n",
      "Step: 6400, Learning_rate:0.0078125, Loss: 0.1637, Accuracy: 96.09%\n",
      "Step: 6500, Learning_rate:0.0078125, Loss: 0.2178, Accuracy: 93.75%\n",
      "Step: 6600, Learning_rate:0.0078125, Loss: 0.1567, Accuracy: 94.53%\n",
      "Step: 6700, Learning_rate:0.0078125, Loss: 0.1929, Accuracy: 92.19%\n",
      "Step: 6800, Learning_rate:0.0078125, Loss: 0.1590, Accuracy: 95.31%\n",
      "Step: 6900, Learning_rate:0.0078125, Loss: 0.1664, Accuracy: 95.31%\n",
      "Step: 7000, Learning_rate:0.00390625, Loss: 0.1412, Accuracy: 96.88%\n",
      "Step: 7100, Learning_rate:0.00390625, Loss: 0.1023, Accuracy: 96.09%\n",
      "Step: 7200, Learning_rate:0.00390625, Loss: 0.1090, Accuracy: 96.88%\n",
      "Step: 7300, Learning_rate:0.00390625, Loss: 0.1480, Accuracy: 96.09%\n",
      "Step: 7400, Learning_rate:0.00390625, Loss: 0.1705, Accuracy: 94.53%\n",
      "Step: 7500, Learning_rate:0.00390625, Loss: 0.1619, Accuracy: 96.09%\n",
      "Step: 7600, Learning_rate:0.00390625, Loss: 0.1228, Accuracy: 96.88%\n",
      "Step: 7700, Learning_rate:0.00390625, Loss: 0.1039, Accuracy: 97.66%\n",
      "Step: 7800, Learning_rate:0.00390625, Loss: 0.1416, Accuracy: 95.31%\n",
      "Step: 7900, Learning_rate:0.00390625, Loss: 0.0666, Accuracy: 97.66%\n",
      "Step: 8000, Learning_rate:0.001953125, Loss: 0.1724, Accuracy: 96.88%\n",
      "Step: 8100, Learning_rate:0.001953125, Loss: 0.1045, Accuracy: 97.66%\n",
      "Step: 8200, Learning_rate:0.001953125, Loss: 0.1922, Accuracy: 94.53%\n",
      "Step: 8300, Learning_rate:0.001953125, Loss: 0.0989, Accuracy: 96.09%\n",
      "Step: 8400, Learning_rate:0.001953125, Loss: 0.1525, Accuracy: 95.31%\n",
      "Step: 8500, Learning_rate:0.001953125, Loss: 0.0634, Accuracy: 97.66%\n",
      "Step: 8600, Learning_rate:0.001953125, Loss: 0.1237, Accuracy: 93.75%\n",
      "Step: 8700, Learning_rate:0.001953125, Loss: 0.0772, Accuracy: 98.44%\n",
      "Step: 8800, Learning_rate:0.001953125, Loss: 0.1219, Accuracy: 98.44%\n",
      "Step: 8900, Learning_rate:0.001953125, Loss: 0.1275, Accuracy: 96.88%\n",
      "Step: 9000, Learning_rate:0.0009765625, Loss: 0.0927, Accuracy: 96.09%\n",
      "Step: 9100, Learning_rate:0.0009765625, Loss: 0.0675, Accuracy: 97.66%\n",
      "Step: 9200, Learning_rate:0.0009765625, Loss: 0.1237, Accuracy: 96.09%\n",
      "Step: 9300, Learning_rate:0.0009765625, Loss: 0.1923, Accuracy: 93.75%\n",
      "Step: 9400, Learning_rate:0.0009765625, Loss: 0.1299, Accuracy: 96.88%\n",
      "Step: 9500, Learning_rate:0.0009765625, Loss: 0.1536, Accuracy: 95.31%\n",
      "Step: 9600, Learning_rate:0.0009765625, Loss: 0.0839, Accuracy: 97.66%\n",
      "Step: 9700, Learning_rate:0.0009765625, Loss: 0.1509, Accuracy: 97.66%\n",
      "Step: 9800, Learning_rate:0.0009765625, Loss: 0.1296, Accuracy: 96.88%\n",
      "Step: 9900, Learning_rate:0.0009765625, Loss: 0.1787, Accuracy: 93.75%\n",
      "Training Finished, Loss: 0.1788, Accuracy: 95.04%\n"
     ]
    }
   ],
   "source": [
    "for i in range(10000):\n",
    "    batch = mnist.train.next_batch(128)\n",
    "    _, learn_rate,loss_, acu  = sess.run([train_step,learning_rate, loss, accuracy], {x: batch[0], y_: batch[1]})\n",
    "    if i % 100 == 0:\n",
    "        print(\"Step:{:>5}, Learning_rate:{:>5}, Loss:{:>7.4f}, Accuracy:{:>7.2%}\".format(i,learn_rate, loss_, acu))\n",
    "    \n",
    "    \n",
    "loss_, acu = sess.run([loss, accuracy], {x: mnist.test.images, \n",
    "                                        y_: mnist.test.labels})\n",
    "print(\"Training Finished, Loss:{:>7.4f}, Accuracy:{:>7.2%}\".format(loss_, acu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:    0, Learning_rate:  0.5, Loss: 2.3026, Accuracy:  7.03%\n",
      "Step:  100, Learning_rate:  0.5, Loss: 2.2998, Accuracy: 14.06%\n",
      "Step:  200, Learning_rate:  0.5, Loss: 2.2950, Accuracy: 13.28%\n",
      "Step:  300, Learning_rate:  0.5, Loss: 2.3039, Accuracy: 10.94%\n",
      "Step:  400, Learning_rate:  0.5, Loss: 2.3045, Accuracy:  8.59%\n",
      "Step:  500, Learning_rate:  0.5, Loss: 2.2990, Accuracy: 13.28%\n",
      "Step:  600, Learning_rate:  0.5, Loss: 2.3016, Accuracy:  9.38%\n",
      "Step:  700, Learning_rate:  0.5, Loss: 2.3092, Accuracy:  7.03%\n",
      "Step:  800, Learning_rate:  0.5, Loss: 2.3049, Accuracy: 11.72%\n",
      "Step:  900, Learning_rate:  0.5, Loss: 2.3037, Accuracy: 10.94%\n",
      "Step: 1000, Learning_rate:  0.5, Loss: 2.3132, Accuracy:  7.81%\n",
      "Step: 1100, Learning_rate:  0.5, Loss: 2.3102, Accuracy:  7.03%\n",
      "Step: 1200, Learning_rate:  0.5, Loss: 2.3067, Accuracy:  9.38%\n",
      "Step: 1300, Learning_rate:  0.5, Loss: 2.3114, Accuracy: 10.94%\n",
      "Step: 1400, Learning_rate:  0.5, Loss: 2.3180, Accuracy:  6.25%\n",
      "Step: 1500, Learning_rate:  0.5, Loss: 2.2945, Accuracy: 13.28%\n",
      "Step: 1600, Learning_rate:  0.5, Loss: 2.2939, Accuracy: 14.06%\n",
      "Step: 1700, Learning_rate:  0.5, Loss: 2.2983, Accuracy: 14.06%\n",
      "Step: 1800, Learning_rate:  0.5, Loss: 2.2946, Accuracy: 13.28%\n",
      "Step: 1900, Learning_rate:  0.5, Loss: 2.3015, Accuracy: 10.16%\n",
      "Step: 2000, Learning_rate:  0.5, Loss: 2.2925, Accuracy: 14.84%\n",
      "Step: 2100, Learning_rate:  0.5, Loss: 2.3054, Accuracy: 10.16%\n",
      "Step: 2200, Learning_rate:  0.5, Loss: 2.3007, Accuracy: 14.84%\n",
      "Step: 2300, Learning_rate:  0.5, Loss: 2.3118, Accuracy:  7.03%\n",
      "Step: 2400, Learning_rate:  0.5, Loss: 2.3200, Accuracy:  4.69%\n",
      "Step: 2500, Learning_rate:  0.5, Loss: 2.2980, Accuracy: 12.50%\n",
      "Step: 2600, Learning_rate:  0.5, Loss: 2.3138, Accuracy:  7.81%\n",
      "Step: 2700, Learning_rate:  0.5, Loss: 2.3136, Accuracy:  7.03%\n",
      "Step: 2800, Learning_rate:  0.5, Loss: 2.2976, Accuracy:  8.59%\n",
      "Step: 2900, Learning_rate:  0.5, Loss: 2.3052, Accuracy: 13.28%\n",
      "Step: 3000, Learning_rate:  0.5, Loss: 2.2918, Accuracy: 17.19%\n",
      "Step: 3100, Learning_rate:  0.5, Loss: 2.3098, Accuracy: 10.16%\n",
      "Step: 3200, Learning_rate:  0.5, Loss: 2.2998, Accuracy:  9.38%\n",
      "Step: 3300, Learning_rate:  0.5, Loss: 2.2958, Accuracy: 15.62%\n",
      "Step: 3400, Learning_rate:  0.5, Loss: 2.3086, Accuracy:  9.38%\n",
      "Step: 3500, Learning_rate:  0.5, Loss: 2.3013, Accuracy: 10.16%\n",
      "Step: 3600, Learning_rate:  0.5, Loss: 2.2998, Accuracy: 12.50%\n",
      "Step: 3700, Learning_rate:  0.5, Loss: 2.2992, Accuracy: 14.06%\n",
      "Step: 3800, Learning_rate:  0.5, Loss: 2.2964, Accuracy: 15.62%\n",
      "Step: 3900, Learning_rate:  0.5, Loss: 2.2943, Accuracy: 17.19%\n",
      "Step: 4000, Learning_rate:  0.5, Loss: 2.2965, Accuracy: 15.62%\n",
      "Step: 4100, Learning_rate:  0.5, Loss: 2.3155, Accuracy:  7.03%\n",
      "Step: 4200, Learning_rate:  0.5, Loss: 2.2984, Accuracy: 14.06%\n",
      "Step: 4300, Learning_rate:  0.5, Loss: 2.2994, Accuracy: 12.50%\n",
      "Step: 4400, Learning_rate:  0.5, Loss: 2.3078, Accuracy: 10.16%\n",
      "Step: 4500, Learning_rate:  0.5, Loss: 2.2962, Accuracy:  7.81%\n",
      "Step: 4600, Learning_rate:  0.5, Loss: 2.2962, Accuracy:  7.81%\n",
      "Step: 4700, Learning_rate:  0.5, Loss: 2.3227, Accuracy:  7.03%\n",
      "Step: 4800, Learning_rate:  0.5, Loss: 2.3027, Accuracy:  9.38%\n",
      "Step: 4900, Learning_rate:  0.5, Loss: 2.3110, Accuracy:  7.03%\n",
      "Step: 5000, Learning_rate:  0.5, Loss: 2.3058, Accuracy: 11.72%\n",
      "Step: 5100, Learning_rate:  0.5, Loss: 2.3023, Accuracy: 10.94%\n",
      "Step: 5200, Learning_rate:  0.5, Loss: 2.3048, Accuracy:  9.38%\n",
      "Step: 5300, Learning_rate:  0.5, Loss: 2.3026, Accuracy:  8.59%\n",
      "Step: 5400, Learning_rate:  0.5, Loss: 2.3080, Accuracy:  9.38%\n",
      "Step: 5500, Learning_rate:  0.5, Loss: 2.3063, Accuracy:  9.38%\n",
      "Step: 5600, Learning_rate:  0.5, Loss: 2.3081, Accuracy:  9.38%\n",
      "Step: 5700, Learning_rate:  0.5, Loss: 2.3010, Accuracy:  8.59%\n",
      "Step: 5800, Learning_rate:  0.5, Loss: 2.2994, Accuracy: 13.28%\n",
      "Step: 5900, Learning_rate:  0.5, Loss: 2.3054, Accuracy: 10.94%\n",
      "Step: 6000, Learning_rate:  0.5, Loss: 2.3050, Accuracy: 11.72%\n",
      "Step: 6100, Learning_rate:  0.5, Loss: 2.2892, Accuracy: 17.19%\n",
      "Step: 6200, Learning_rate:  0.5, Loss: 2.3059, Accuracy: 15.62%\n",
      "Step: 6300, Learning_rate:  0.5, Loss: 2.2959, Accuracy: 11.72%\n",
      "Step: 6400, Learning_rate:  0.5, Loss: 2.3082, Accuracy:  8.59%\n",
      "Step: 6500, Learning_rate:  0.5, Loss: 2.3142, Accuracy: 10.94%\n",
      "Step: 6600, Learning_rate:  0.5, Loss: 2.2989, Accuracy: 14.84%\n",
      "Step: 6700, Learning_rate:  0.5, Loss: 2.2974, Accuracy: 16.41%\n",
      "Step: 6800, Learning_rate:  0.5, Loss: 2.3053, Accuracy: 10.16%\n",
      "Step: 6900, Learning_rate:  0.5, Loss: 2.3100, Accuracy:  6.25%\n",
      "Step: 7000, Learning_rate:  0.5, Loss: 2.3071, Accuracy: 10.16%\n",
      "Step: 7100, Learning_rate:  0.5, Loss: 2.2903, Accuracy: 14.06%\n",
      "Step: 7200, Learning_rate:  0.5, Loss: 2.3049, Accuracy:  9.38%\n",
      "Step: 7300, Learning_rate:  0.5, Loss: 2.2955, Accuracy: 12.50%\n",
      "Step: 7400, Learning_rate:  0.5, Loss: 2.2985, Accuracy: 13.28%\n",
      "Step: 7500, Learning_rate:  0.5, Loss: 2.3125, Accuracy:  3.91%\n",
      "Step: 7600, Learning_rate:  0.5, Loss: 2.3095, Accuracy:  8.59%\n",
      "Step: 7700, Learning_rate:  0.5, Loss: 2.3061, Accuracy:  8.59%\n",
      "Step: 7800, Learning_rate:  0.5, Loss: 2.2946, Accuracy: 14.84%\n",
      "Step: 7900, Learning_rate:  0.5, Loss: 2.2991, Accuracy: 14.06%\n",
      "Step: 8000, Learning_rate:  0.5, Loss: 2.2946, Accuracy: 13.28%\n",
      "Step: 8100, Learning_rate:  0.5, Loss: 2.2915, Accuracy: 15.62%\n",
      "Step: 8200, Learning_rate:  0.5, Loss: 2.3012, Accuracy: 12.50%\n",
      "Step: 8300, Learning_rate:  0.5, Loss: 2.3004, Accuracy: 11.72%\n",
      "Step: 8400, Learning_rate:  0.5, Loss: 2.2970, Accuracy: 13.28%\n",
      "Step: 8500, Learning_rate:  0.5, Loss: 2.2901, Accuracy:  7.81%\n",
      "Step: 8600, Learning_rate:  0.5, Loss: 1.7292, Accuracy: 28.91%\n",
      "Step: 8700, Learning_rate:  0.5, Loss: 1.8155, Accuracy: 34.38%\n",
      "Step: 8800, Learning_rate:  0.5, Loss: 1.6567, Accuracy: 27.34%\n",
      "Step: 8900, Learning_rate:  0.5, Loss: 1.2302, Accuracy: 46.88%\n",
      "Step: 9000, Learning_rate:  0.5, Loss: 1.3356, Accuracy: 49.22%\n",
      "Step: 9100, Learning_rate:  0.5, Loss: 0.9719, Accuracy: 55.47%\n",
      "Step: 9200, Learning_rate:  0.5, Loss: 0.9586, Accuracy: 62.50%\n",
      "Step: 9300, Learning_rate:  0.5, Loss: 0.9509, Accuracy: 68.75%\n",
      "Step: 9400, Learning_rate:  0.5, Loss: 0.6737, Accuracy: 78.91%\n",
      "Step: 9500, Learning_rate:  0.5, Loss: 0.6616, Accuracy: 71.88%\n",
      "Step: 9600, Learning_rate:  0.5, Loss: 0.6484, Accuracy: 85.16%\n",
      "Step: 9700, Learning_rate:  0.5, Loss: 0.5783, Accuracy: 83.59%\n",
      "Step: 9800, Learning_rate:  0.5, Loss: 0.3419, Accuracy: 92.97%\n",
      "Step: 9900, Learning_rate:  0.5, Loss: 1.1110, Accuracy: 68.75%\n",
      "Training Finished, Loss: 0.5746, Accuracy: 84.74%\n"
     ]
    }
   ],
   "source": [
    "for i in range(10000):\n",
    "    batch = mnist.train.next_batch(128)\n",
    "    _, loss_, acu  = sess.run([train_step, loss, accuracy], {x: batch[0], y_: batch[1]})\n",
    "    if i % 100 == 0:\n",
    "        print(\"Step:{:>5}, Learning_rate:{:>5}, Loss:{:>7.4f}, Accuracy:{:>7.2%}\".format(i,learning_rate, loss_, acu))\n",
    "    \n",
    "    \n",
    "loss_, acu = sess.run([loss, accuracy], {x: mnist.test.images, \n",
    "                                        y_: mnist.test.labels})\n",
    "print(\"Training Finished, Loss:{:>7.4f}, Accuracy:{:>7.2%}\".format(loss_, acu))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 结论： 学习率太大容易学习不充分， 当学习率随着训练步数增加逐渐减小时，更容易学到比较好的特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
