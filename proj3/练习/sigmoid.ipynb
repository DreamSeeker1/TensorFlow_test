{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 多层sigmoid梯度消失练习"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liuyanfang/anaconda3/envs/tensorflow1.4/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ./MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('./MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer1 = tf.layers.dense(inputs=x, \n",
    "                         units=20, \n",
    "                         activation=tf.nn.sigmoid,                        \n",
    "                         bias_initializer=tf.constant_initializer(0),\n",
    "                         kernel_initializer=tf.truncated_normal_initializer(stddev=0.1)\n",
    "                        )\n",
    "layer2 = tf.layers.dense(inputs=layer1, \n",
    "                         units=20, \n",
    "                         activation=tf.nn.sigmoid,                        \n",
    "                         bias_initializer=tf.constant_initializer(0),\n",
    "                         kernel_initializer=tf.truncated_normal_initializer(stddev=0.1)\n",
    "                        )\n",
    "layer3 = tf.layers.dense(inputs=layer2, \n",
    "                         units=20, \n",
    "                         activation=tf.nn.sigmoid,                        \n",
    "                         bias_initializer=tf.constant_initializer(0),\n",
    "                         kernel_initializer=tf.truncated_normal_initializer(stddev=0.1)\n",
    "                        )\n",
    "layer4 = tf.layers.dense(inputs=layer3, \n",
    "                         units=20, \n",
    "                         activation=tf.nn.sigmoid,                        \n",
    "                         bias_initializer=tf.constant_initializer(0),\n",
    "                         kernel_initializer=tf.truncated_normal_initializer(stddev=0.1)\n",
    "                        )\n",
    "layer5 = tf.layers.dense(inputs=layer4, \n",
    "                         units=20, \n",
    "                         activation=tf.nn.sigmoid,                        \n",
    "                         bias_initializer=tf.constant_initializer(0),\n",
    "                         kernel_initializer=tf.truncated_normal_initializer(stddev=0.1)\n",
    "                        )\n",
    "layer6 = tf.layers.dense(inputs=layer5, \n",
    "                         units=20, \n",
    "                         activation=tf.nn.sigmoid,                        \n",
    "                         bias_initializer=tf.constant_initializer(0),\n",
    "                         kernel_initializer=tf.truncated_normal_initializer(stddev=0.1)\n",
    "                        )\n",
    "y = tf.layers.dense(inputs=layer6, \n",
    "                    units=10, \n",
    "                    activation=None, \n",
    "                    bias_initializer=tf.constant_initializer(0), \n",
    "                    kernel_initializer=tf.truncated_normal_initializer(stddev=0.1)\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_step = tf.train.GradientDescentOptimizer(0.01).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax_result = tf.nn.softmax(y)\n",
    "pred = tf.argmax(softmax_result, axis=1)\n",
    "true = tf.argmax(y_, axis=1)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(pred, true), tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:    0, Loss: 2.3370, Accuracy:  6.25%\n",
      "Step:  100, Loss: 2.3061, Accuracy: 11.72%\n",
      "Step:  200, Loss: 2.3026, Accuracy:  9.38%\n",
      "Step:  300, Loss: 2.3151, Accuracy:  7.03%\n",
      "Step:  400, Loss: 2.2985, Accuracy: 12.50%\n",
      "Step:  500, Loss: 2.3019, Accuracy: 11.72%\n",
      "Step:  600, Loss: 2.3060, Accuracy:  9.38%\n",
      "Step:  700, Loss: 2.3049, Accuracy:  7.03%\n",
      "Step:  800, Loss: 2.3069, Accuracy:  7.03%\n",
      "Step:  900, Loss: 2.2936, Accuracy: 16.41%\n",
      "Step: 1000, Loss: 2.3029, Accuracy:  9.38%\n",
      "Step: 1100, Loss: 2.2937, Accuracy: 17.97%\n",
      "Step: 1200, Loss: 2.3008, Accuracy:  9.38%\n",
      "Step: 1300, Loss: 2.3077, Accuracy: 10.16%\n",
      "Step: 1400, Loss: 2.3091, Accuracy:  6.25%\n",
      "Step: 1500, Loss: 2.2952, Accuracy: 16.41%\n",
      "Step: 1600, Loss: 2.3073, Accuracy: 10.16%\n",
      "Step: 1700, Loss: 2.3102, Accuracy:  7.03%\n",
      "Step: 1800, Loss: 2.2973, Accuracy: 14.06%\n",
      "Step: 1900, Loss: 2.3040, Accuracy:  9.38%\n",
      "Step: 2000, Loss: 2.3071, Accuracy: 11.72%\n",
      "Step: 2100, Loss: 2.2985, Accuracy: 10.16%\n",
      "Step: 2200, Loss: 2.2998, Accuracy: 14.06%\n",
      "Step: 2300, Loss: 2.3024, Accuracy:  7.81%\n",
      "Step: 2400, Loss: 2.3005, Accuracy: 10.16%\n",
      "Step: 2500, Loss: 2.2972, Accuracy: 13.28%\n",
      "Step: 2600, Loss: 2.2898, Accuracy: 21.88%\n",
      "Step: 2700, Loss: 2.3045, Accuracy: 12.50%\n",
      "Step: 2800, Loss: 2.3105, Accuracy:  7.81%\n",
      "Step: 2900, Loss: 2.3076, Accuracy:  8.59%\n",
      "Step: 3000, Loss: 2.3072, Accuracy:  7.81%\n",
      "Step: 3100, Loss: 2.2953, Accuracy: 14.06%\n",
      "Step: 3200, Loss: 2.3059, Accuracy: 10.16%\n",
      "Step: 3300, Loss: 2.3018, Accuracy: 11.72%\n",
      "Step: 3400, Loss: 2.3021, Accuracy:  8.59%\n",
      "Step: 3500, Loss: 2.3061, Accuracy: 11.72%\n",
      "Step: 3600, Loss: 2.3145, Accuracy:  5.47%\n",
      "Step: 3700, Loss: 2.2976, Accuracy: 13.28%\n",
      "Step: 3800, Loss: 2.3068, Accuracy: 10.94%\n",
      "Step: 3900, Loss: 2.3005, Accuracy: 11.72%\n",
      "Step: 4000, Loss: 2.3019, Accuracy: 10.94%\n",
      "Step: 4100, Loss: 2.3048, Accuracy:  8.59%\n",
      "Step: 4200, Loss: 2.3060, Accuracy:  8.59%\n",
      "Step: 4300, Loss: 2.2999, Accuracy: 10.94%\n",
      "Step: 4400, Loss: 2.2927, Accuracy: 20.31%\n",
      "Step: 4500, Loss: 2.3020, Accuracy: 12.50%\n",
      "Step: 4600, Loss: 2.3025, Accuracy: 11.72%\n",
      "Step: 4700, Loss: 2.3040, Accuracy: 10.94%\n",
      "Step: 4800, Loss: 2.2987, Accuracy: 10.94%\n",
      "Step: 4900, Loss: 2.3026, Accuracy: 14.06%\n",
      "Step: 5000, Loss: 2.3069, Accuracy:  5.47%\n",
      "Step: 5100, Loss: 2.2988, Accuracy: 10.94%\n",
      "Step: 5200, Loss: 2.3002, Accuracy: 10.94%\n",
      "Step: 5300, Loss: 2.3048, Accuracy: 10.16%\n",
      "Step: 5400, Loss: 2.2966, Accuracy: 13.28%\n",
      "Step: 5500, Loss: 2.3000, Accuracy: 12.50%\n",
      "Step: 5600, Loss: 2.3042, Accuracy:  7.81%\n",
      "Step: 5700, Loss: 2.2925, Accuracy: 14.84%\n",
      "Step: 5800, Loss: 2.3121, Accuracy:  7.03%\n",
      "Step: 5900, Loss: 2.2926, Accuracy: 17.97%\n",
      "Step: 6000, Loss: 2.3100, Accuracy:  7.03%\n",
      "Step: 6100, Loss: 2.2997, Accuracy: 14.06%\n",
      "Step: 6200, Loss: 2.2997, Accuracy: 13.28%\n",
      "Step: 6300, Loss: 2.3043, Accuracy:  8.59%\n",
      "Step: 6400, Loss: 2.2991, Accuracy: 10.16%\n",
      "Step: 6500, Loss: 2.3046, Accuracy: 14.84%\n",
      "Step: 6600, Loss: 2.2933, Accuracy: 14.84%\n",
      "Step: 6700, Loss: 2.3004, Accuracy: 10.94%\n",
      "Step: 6800, Loss: 2.3061, Accuracy:  9.38%\n",
      "Step: 6900, Loss: 2.3034, Accuracy: 13.28%\n",
      "Step: 7000, Loss: 2.3012, Accuracy: 11.72%\n",
      "Step: 7100, Loss: 2.3033, Accuracy: 10.94%\n",
      "Step: 7200, Loss: 2.3101, Accuracy:  9.38%\n",
      "Step: 7300, Loss: 2.3029, Accuracy: 10.16%\n",
      "Step: 7400, Loss: 2.3017, Accuracy: 11.72%\n",
      "Step: 7500, Loss: 2.3025, Accuracy: 11.72%\n",
      "Step: 7600, Loss: 2.2977, Accuracy: 12.50%\n",
      "Step: 7700, Loss: 2.3026, Accuracy: 12.50%\n",
      "Step: 7800, Loss: 2.2955, Accuracy: 19.53%\n",
      "Step: 7900, Loss: 2.3045, Accuracy:  9.38%\n",
      "Step: 8000, Loss: 2.3098, Accuracy:  8.59%\n",
      "Step: 8100, Loss: 2.3063, Accuracy:  7.81%\n",
      "Step: 8200, Loss: 2.2973, Accuracy: 15.62%\n",
      "Step: 8300, Loss: 2.2991, Accuracy: 14.06%\n",
      "Step: 8400, Loss: 2.3004, Accuracy: 12.50%\n",
      "Step: 8500, Loss: 2.2953, Accuracy: 12.50%\n",
      "Step: 8600, Loss: 2.2964, Accuracy: 14.84%\n",
      "Step: 8700, Loss: 2.3090, Accuracy:  7.03%\n",
      "Step: 8800, Loss: 2.3018, Accuracy: 11.72%\n",
      "Step: 8900, Loss: 2.3019, Accuracy: 10.16%\n",
      "Step: 9000, Loss: 2.3036, Accuracy: 10.94%\n",
      "Step: 9100, Loss: 2.3032, Accuracy: 10.16%\n",
      "Step: 9200, Loss: 2.2970, Accuracy: 14.84%\n",
      "Step: 9300, Loss: 2.2960, Accuracy: 15.62%\n",
      "Step: 9400, Loss: 2.3035, Accuracy: 10.94%\n",
      "Step: 9500, Loss: 2.3021, Accuracy: 10.16%\n",
      "Step: 9600, Loss: 2.2984, Accuracy: 14.06%\n",
      "Step: 9700, Loss: 2.3064, Accuracy:  9.38%\n",
      "Step: 9800, Loss: 2.3021, Accuracy: 11.72%\n",
      "Step: 9900, Loss: 2.2936, Accuracy: 14.06%\n",
      "Step:10000, Loss: 2.2995, Accuracy: 11.72%\n",
      "Step:10100, Loss: 2.3050, Accuracy: 10.16%\n",
      "Step:10200, Loss: 2.3026, Accuracy: 10.94%\n",
      "Step:10300, Loss: 2.3025, Accuracy:  8.59%\n",
      "Step:10400, Loss: 2.2993, Accuracy: 12.50%\n",
      "Step:10500, Loss: 2.3120, Accuracy:  7.03%\n",
      "Step:10600, Loss: 2.3044, Accuracy:  8.59%\n",
      "Step:10700, Loss: 2.3024, Accuracy: 11.72%\n",
      "Step:10800, Loss: 2.3030, Accuracy: 12.50%\n",
      "Step:10900, Loss: 2.2982, Accuracy: 11.72%\n",
      "Step:11000, Loss: 2.3029, Accuracy: 10.94%\n",
      "Step:11100, Loss: 2.3040, Accuracy: 10.94%\n",
      "Step:11200, Loss: 2.2969, Accuracy: 13.28%\n",
      "Step:11300, Loss: 2.2995, Accuracy: 11.72%\n",
      "Step:11400, Loss: 2.3034, Accuracy:  8.59%\n",
      "Step:11500, Loss: 2.2979, Accuracy: 14.06%\n",
      "Step:11600, Loss: 2.2910, Accuracy: 17.19%\n",
      "Step:11700, Loss: 2.3062, Accuracy: 10.94%\n",
      "Step:11800, Loss: 2.2994, Accuracy: 13.28%\n",
      "Step:11900, Loss: 2.2967, Accuracy: 14.06%\n",
      "Step:12000, Loss: 2.3085, Accuracy:  9.38%\n",
      "Step:12100, Loss: 2.2988, Accuracy: 14.84%\n",
      "Step:12200, Loss: 2.3014, Accuracy: 10.94%\n",
      "Step:12300, Loss: 2.3025, Accuracy: 10.16%\n",
      "Step:12400, Loss: 2.3000, Accuracy: 10.94%\n",
      "Step:12500, Loss: 2.2976, Accuracy: 14.06%\n",
      "Step:12600, Loss: 2.3002, Accuracy: 13.28%\n",
      "Step:12700, Loss: 2.3033, Accuracy:  9.38%\n",
      "Step:12800, Loss: 2.2994, Accuracy: 13.28%\n",
      "Step:12900, Loss: 2.3009, Accuracy: 10.94%\n",
      "Step:13000, Loss: 2.3021, Accuracy: 12.50%\n",
      "Step:13100, Loss: 2.2998, Accuracy: 10.16%\n",
      "Step:13200, Loss: 2.3014, Accuracy: 10.16%\n",
      "Step:13300, Loss: 2.3025, Accuracy: 10.94%\n",
      "Step:13400, Loss: 2.3081, Accuracy:  6.25%\n",
      "Step:13500, Loss: 2.3033, Accuracy: 11.72%\n",
      "Step:13600, Loss: 2.3041, Accuracy: 12.50%\n",
      "Step:13700, Loss: 2.2987, Accuracy: 14.06%\n",
      "Step:13800, Loss: 2.2991, Accuracy: 15.62%\n",
      "Step:13900, Loss: 2.2980, Accuracy:  9.38%\n",
      "Step:14000, Loss: 2.2914, Accuracy: 17.19%\n",
      "Step:14100, Loss: 2.3055, Accuracy:  8.59%\n",
      "Step:14200, Loss: 2.3033, Accuracy: 10.16%\n",
      "Step:14300, Loss: 2.3062, Accuracy:  8.59%\n",
      "Step:14400, Loss: 2.3033, Accuracy: 10.94%\n",
      "Step:14500, Loss: 2.3069, Accuracy:  7.03%\n",
      "Step:14600, Loss: 2.2974, Accuracy: 12.50%\n",
      "Step:14700, Loss: 2.3071, Accuracy:  9.38%\n",
      "Step:14800, Loss: 2.3019, Accuracy:  7.03%\n",
      "Step:14900, Loss: 2.2937, Accuracy: 15.62%\n",
      "Step:15000, Loss: 2.3010, Accuracy:  9.38%\n",
      "Step:15100, Loss: 2.3009, Accuracy: 11.72%\n",
      "Step:15200, Loss: 2.2974, Accuracy: 12.50%\n",
      "Step:15300, Loss: 2.3057, Accuracy:  9.38%\n",
      "Step:15400, Loss: 2.3027, Accuracy:  9.38%\n",
      "Step:15500, Loss: 2.3076, Accuracy:  9.38%\n",
      "Step:15600, Loss: 2.2960, Accuracy: 12.50%\n",
      "Step:15700, Loss: 2.2929, Accuracy: 14.84%\n",
      "Step:15800, Loss: 2.3062, Accuracy:  6.25%\n",
      "Step:15900, Loss: 2.3011, Accuracy:  8.59%\n",
      "Step:16000, Loss: 2.3052, Accuracy:  8.59%\n",
      "Step:16100, Loss: 2.2941, Accuracy: 15.62%\n",
      "Step:16200, Loss: 2.3034, Accuracy:  9.38%\n",
      "Step:16300, Loss: 2.3025, Accuracy: 10.94%\n",
      "Step:16400, Loss: 2.2941, Accuracy: 14.06%\n",
      "Step:16500, Loss: 2.3017, Accuracy: 13.28%\n",
      "Step:16600, Loss: 2.3048, Accuracy: 10.16%\n",
      "Step:16700, Loss: 2.2974, Accuracy: 13.28%\n",
      "Step:16800, Loss: 2.3021, Accuracy:  9.38%\n",
      "Step:16900, Loss: 2.3039, Accuracy:  8.59%\n",
      "Step:17000, Loss: 2.3004, Accuracy: 12.50%\n",
      "Step:17100, Loss: 2.3016, Accuracy: 13.28%\n",
      "Step:17200, Loss: 2.2941, Accuracy: 15.62%\n",
      "Step:17300, Loss: 2.3045, Accuracy: 12.50%\n",
      "Step:17400, Loss: 2.3006, Accuracy:  8.59%\n",
      "Step:17500, Loss: 2.2903, Accuracy: 17.19%\n",
      "Step:17600, Loss: 2.3028, Accuracy: 10.94%\n",
      "Step:17700, Loss: 2.3039, Accuracy: 10.16%\n",
      "Step:17800, Loss: 2.3008, Accuracy: 11.72%\n",
      "Step:17900, Loss: 2.3097, Accuracy:  5.47%\n",
      "Step:18000, Loss: 2.3016, Accuracy: 10.16%\n",
      "Step:18100, Loss: 2.2949, Accuracy: 15.62%\n",
      "Step:18200, Loss: 2.2990, Accuracy: 11.72%\n",
      "Step:18300, Loss: 2.2961, Accuracy: 15.62%\n",
      "Step:18400, Loss: 2.2949, Accuracy: 14.84%\n",
      "Step:18500, Loss: 2.3091, Accuracy:  7.81%\n",
      "Step:18600, Loss: 2.3058, Accuracy: 10.16%\n",
      "Step:18700, Loss: 2.3029, Accuracy: 12.50%\n",
      "Step:18800, Loss: 2.2966, Accuracy: 13.28%\n",
      "Step:18900, Loss: 2.3045, Accuracy:  7.81%\n",
      "Step:19000, Loss: 2.3046, Accuracy:  6.25%\n",
      "Step:19100, Loss: 2.3050, Accuracy:  7.81%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:19200, Loss: 2.2963, Accuracy: 14.84%\n",
      "Step:19300, Loss: 2.3075, Accuracy:  9.38%\n",
      "Step:19400, Loss: 2.2996, Accuracy: 14.06%\n",
      "Step:19500, Loss: 2.3042, Accuracy:  7.81%\n",
      "Step:19600, Loss: 2.2975, Accuracy: 12.50%\n",
      "Step:19700, Loss: 2.3033, Accuracy: 10.16%\n",
      "Step:19800, Loss: 2.2972, Accuracy: 14.06%\n",
      "Step:19900, Loss: 2.3060, Accuracy:  7.03%\n",
      "Step:20000, Loss: 2.2994, Accuracy:  9.38%\n",
      "Step:20100, Loss: 2.2960, Accuracy: 13.28%\n",
      "Step:20200, Loss: 2.3038, Accuracy: 12.50%\n",
      "Step:20300, Loss: 2.2927, Accuracy: 18.75%\n",
      "Step:20400, Loss: 2.2962, Accuracy: 14.84%\n",
      "Step:20500, Loss: 2.2994, Accuracy: 11.72%\n",
      "Step:20600, Loss: 2.3074, Accuracy:  9.38%\n",
      "Step:20700, Loss: 2.2943, Accuracy: 15.62%\n",
      "Step:20800, Loss: 2.3036, Accuracy: 11.72%\n",
      "Step:20900, Loss: 2.3017, Accuracy: 12.50%\n",
      "Step:21000, Loss: 2.2994, Accuracy: 10.94%\n",
      "Step:21100, Loss: 2.3101, Accuracy:  5.47%\n",
      "Step:21200, Loss: 2.3065, Accuracy: 10.16%\n",
      "Step:21300, Loss: 2.2988, Accuracy: 11.72%\n",
      "Step:21400, Loss: 2.3015, Accuracy: 10.94%\n",
      "Step:21500, Loss: 2.3054, Accuracy: 10.16%\n",
      "Step:21600, Loss: 2.2929, Accuracy: 16.41%\n",
      "Step:21700, Loss: 2.3082, Accuracy:  9.38%\n",
      "Step:21800, Loss: 2.2989, Accuracy: 14.84%\n",
      "Step:21900, Loss: 2.3011, Accuracy: 10.16%\n",
      "Step:22000, Loss: 2.3000, Accuracy: 10.94%\n",
      "Step:22100, Loss: 2.2997, Accuracy: 13.28%\n",
      "Step:22200, Loss: 2.3037, Accuracy: 12.50%\n",
      "Step:22300, Loss: 2.3000, Accuracy:  9.38%\n",
      "Step:22400, Loss: 2.3024, Accuracy:  9.38%\n",
      "Step:22500, Loss: 2.3007, Accuracy: 13.28%\n",
      "Step:22600, Loss: 2.3041, Accuracy: 10.16%\n",
      "Step:22700, Loss: 2.2952, Accuracy: 18.75%\n",
      "Step:22800, Loss: 2.3078, Accuracy:  9.38%\n",
      "Step:22900, Loss: 2.2963, Accuracy: 12.50%\n",
      "Step:23000, Loss: 2.3000, Accuracy: 12.50%\n",
      "Step:23100, Loss: 2.3061, Accuracy:  7.81%\n",
      "Step:23200, Loss: 2.3064, Accuracy:  7.03%\n",
      "Step:23300, Loss: 2.3004, Accuracy: 11.72%\n",
      "Step:23400, Loss: 2.3103, Accuracy:  4.69%\n",
      "Step:23500, Loss: 2.2993, Accuracy: 13.28%\n",
      "Step:23600, Loss: 2.3111, Accuracy:  5.47%\n",
      "Step:23700, Loss: 2.3056, Accuracy:  9.38%\n",
      "Step:23800, Loss: 2.2944, Accuracy: 15.62%\n",
      "Step:23900, Loss: 2.3121, Accuracy:  4.69%\n",
      "Step:24000, Loss: 2.3074, Accuracy:  7.81%\n",
      "Step:24100, Loss: 2.2911, Accuracy: 20.31%\n",
      "Step:24200, Loss: 2.3053, Accuracy:  8.59%\n",
      "Step:24300, Loss: 2.2933, Accuracy: 13.28%\n",
      "Step:24400, Loss: 2.2975, Accuracy: 13.28%\n",
      "Step:24500, Loss: 2.2938, Accuracy: 13.28%\n",
      "Step:24600, Loss: 2.2992, Accuracy: 12.50%\n",
      "Step:24700, Loss: 2.2974, Accuracy: 11.72%\n",
      "Step:24800, Loss: 2.3091, Accuracy:  8.59%\n",
      "Step:24900, Loss: 2.3113, Accuracy:  4.69%\n",
      "Step:25000, Loss: 2.3102, Accuracy:  7.03%\n",
      "Step:25100, Loss: 2.3020, Accuracy: 10.16%\n",
      "Step:25200, Loss: 2.3035, Accuracy:  6.25%\n",
      "Step:25300, Loss: 2.3054, Accuracy:  9.38%\n",
      "Step:25400, Loss: 2.2999, Accuracy: 11.72%\n",
      "Step:25500, Loss: 2.3015, Accuracy: 12.50%\n",
      "Step:25600, Loss: 2.3055, Accuracy: 10.94%\n",
      "Step:25700, Loss: 2.2988, Accuracy: 14.06%\n",
      "Step:25800, Loss: 2.2940, Accuracy: 14.06%\n",
      "Step:25900, Loss: 2.3082, Accuracy:  6.25%\n",
      "Step:26000, Loss: 2.3027, Accuracy: 12.50%\n",
      "Step:26100, Loss: 2.2921, Accuracy: 14.84%\n",
      "Step:26200, Loss: 2.2993, Accuracy: 11.72%\n",
      "Step:26300, Loss: 2.3053, Accuracy: 11.72%\n",
      "Step:26400, Loss: 2.3053, Accuracy: 10.16%\n",
      "Step:26500, Loss: 2.3082, Accuracy:  9.38%\n",
      "Step:26600, Loss: 2.3097, Accuracy:  9.38%\n",
      "Step:26700, Loss: 2.3013, Accuracy: 10.16%\n",
      "Step:26800, Loss: 2.3038, Accuracy:  9.38%\n",
      "Step:26900, Loss: 2.3017, Accuracy:  9.38%\n",
      "Step:27000, Loss: 2.3044, Accuracy: 10.16%\n",
      "Step:27100, Loss: 2.3067, Accuracy: 10.94%\n",
      "Step:27200, Loss: 2.3041, Accuracy: 10.94%\n",
      "Step:27300, Loss: 2.2963, Accuracy: 15.62%\n",
      "Step:27400, Loss: 2.2886, Accuracy: 21.09%\n",
      "Step:27500, Loss: 2.3036, Accuracy: 12.50%\n",
      "Step:27600, Loss: 2.3104, Accuracy:  7.81%\n",
      "Step:27700, Loss: 2.3044, Accuracy: 10.94%\n",
      "Step:27800, Loss: 2.2956, Accuracy: 13.28%\n",
      "Step:27900, Loss: 2.2986, Accuracy: 10.94%\n",
      "Step:28000, Loss: 2.3051, Accuracy:  9.38%\n",
      "Step:28100, Loss: 2.3034, Accuracy: 10.94%\n",
      "Step:28200, Loss: 2.3010, Accuracy: 10.94%\n",
      "Step:28300, Loss: 2.2968, Accuracy: 15.62%\n",
      "Step:28400, Loss: 2.3012, Accuracy: 12.50%\n",
      "Step:28500, Loss: 2.3013, Accuracy: 12.50%\n",
      "Step:28600, Loss: 2.2945, Accuracy: 17.97%\n",
      "Step:28700, Loss: 2.2900, Accuracy: 19.53%\n",
      "Step:28800, Loss: 2.3031, Accuracy:  8.59%\n",
      "Step:28900, Loss: 2.3061, Accuracy:  9.38%\n",
      "Step:29000, Loss: 2.2975, Accuracy: 16.41%\n",
      "Step:29100, Loss: 2.2999, Accuracy:  9.38%\n",
      "Step:29200, Loss: 2.3079, Accuracy:  9.38%\n",
      "Step:29300, Loss: 2.2983, Accuracy: 13.28%\n",
      "Step:29400, Loss: 2.3108, Accuracy:  8.59%\n",
      "Step:29500, Loss: 2.3036, Accuracy:  9.38%\n",
      "Step:29600, Loss: 2.2941, Accuracy: 11.72%\n",
      "Step:29700, Loss: 2.3036, Accuracy: 10.94%\n",
      "Step:29800, Loss: 2.3042, Accuracy: 10.16%\n",
      "Step:29900, Loss: 2.3048, Accuracy:  7.81%\n",
      "Step:30000, Loss: 2.3087, Accuracy:  9.38%\n",
      "Step:30100, Loss: 2.3026, Accuracy: 10.94%\n",
      "Step:30200, Loss: 2.3069, Accuracy:  8.59%\n",
      "Step:30300, Loss: 2.3028, Accuracy: 11.72%\n",
      "Step:30400, Loss: 2.3039, Accuracy:  8.59%\n",
      "Step:30500, Loss: 2.2977, Accuracy: 10.16%\n",
      "Step:30600, Loss: 2.3064, Accuracy:  7.03%\n",
      "Step:30700, Loss: 2.2968, Accuracy: 13.28%\n",
      "Step:30800, Loss: 2.3014, Accuracy: 13.28%\n",
      "Step:30900, Loss: 2.3023, Accuracy: 14.06%\n",
      "Step:31000, Loss: 2.3043, Accuracy:  8.59%\n",
      "Step:31100, Loss: 2.3038, Accuracy:  9.38%\n",
      "Step:31200, Loss: 2.3043, Accuracy: 11.72%\n",
      "Step:31300, Loss: 2.2976, Accuracy: 12.50%\n",
      "Step:31400, Loss: 2.3020, Accuracy: 11.72%\n",
      "Step:31500, Loss: 2.3079, Accuracy: 10.94%\n",
      "Step:31600, Loss: 2.3032, Accuracy:  9.38%\n",
      "Step:31700, Loss: 2.2966, Accuracy: 10.94%\n",
      "Step:31800, Loss: 2.2995, Accuracy: 12.50%\n",
      "Step:31900, Loss: 2.2996, Accuracy: 10.16%\n",
      "Step:32000, Loss: 2.2962, Accuracy: 12.50%\n",
      "Step:32100, Loss: 2.2943, Accuracy: 14.84%\n",
      "Step:32200, Loss: 2.2980, Accuracy: 14.06%\n",
      "Step:32300, Loss: 2.2957, Accuracy: 14.06%\n",
      "Step:32400, Loss: 2.3020, Accuracy: 12.50%\n",
      "Step:32500, Loss: 2.2982, Accuracy: 12.50%\n",
      "Step:32600, Loss: 2.3056, Accuracy: 10.16%\n",
      "Step:32700, Loss: 2.3032, Accuracy:  9.38%\n",
      "Step:32800, Loss: 2.2972, Accuracy: 12.50%\n",
      "Step:32900, Loss: 2.3000, Accuracy:  9.38%\n",
      "Step:33000, Loss: 2.2994, Accuracy: 10.16%\n",
      "Step:33100, Loss: 2.2957, Accuracy: 13.28%\n",
      "Step:33200, Loss: 2.3021, Accuracy:  8.59%\n",
      "Step:33300, Loss: 2.3031, Accuracy: 13.28%\n",
      "Step:33400, Loss: 2.3101, Accuracy:  5.47%\n",
      "Step:33500, Loss: 2.2978, Accuracy: 11.72%\n",
      "Step:33600, Loss: 2.2989, Accuracy: 10.94%\n",
      "Step:33700, Loss: 2.2997, Accuracy: 14.06%\n",
      "Step:33800, Loss: 2.2963, Accuracy: 14.06%\n",
      "Step:33900, Loss: 2.3042, Accuracy: 11.72%\n",
      "Step:34000, Loss: 2.3019, Accuracy: 13.28%\n",
      "Step:34100, Loss: 2.3042, Accuracy: 11.72%\n",
      "Step:34200, Loss: 2.3006, Accuracy: 12.50%\n",
      "Step:34300, Loss: 2.2979, Accuracy:  8.59%\n",
      "Step:34400, Loss: 2.3042, Accuracy:  9.38%\n",
      "Step:34500, Loss: 2.3059, Accuracy:  5.47%\n",
      "Step:34600, Loss: 2.3014, Accuracy: 13.28%\n",
      "Step:34700, Loss: 2.3019, Accuracy: 14.84%\n",
      "Step:34800, Loss: 2.2969, Accuracy: 14.84%\n",
      "Step:34900, Loss: 2.2993, Accuracy: 12.50%\n",
      "Step:35000, Loss: 2.3030, Accuracy: 10.16%\n",
      "Step:35100, Loss: 2.2985, Accuracy: 14.84%\n",
      "Step:35200, Loss: 2.3072, Accuracy:  9.38%\n",
      "Step:35300, Loss: 2.2905, Accuracy: 14.84%\n",
      "Step:35400, Loss: 2.3104, Accuracy: 10.16%\n",
      "Step:35500, Loss: 2.2984, Accuracy: 14.06%\n",
      "Step:35600, Loss: 2.3094, Accuracy: 10.94%\n",
      "Step:35700, Loss: 2.3006, Accuracy: 12.50%\n",
      "Step:35800, Loss: 2.2959, Accuracy: 14.06%\n",
      "Step:35900, Loss: 2.3019, Accuracy: 14.06%\n",
      "Step:36000, Loss: 2.3019, Accuracy:  9.38%\n",
      "Step:36100, Loss: 2.2995, Accuracy: 11.72%\n",
      "Step:36200, Loss: 2.3034, Accuracy:  8.59%\n",
      "Step:36300, Loss: 2.3106, Accuracy:  7.81%\n",
      "Step:36400, Loss: 2.3014, Accuracy:  7.81%\n",
      "Step:36500, Loss: 2.2984, Accuracy: 10.94%\n",
      "Step:36600, Loss: 2.2982, Accuracy: 14.84%\n",
      "Step:36700, Loss: 2.3039, Accuracy:  8.59%\n",
      "Step:36800, Loss: 2.2958, Accuracy: 11.72%\n",
      "Step:36900, Loss: 2.2962, Accuracy: 11.72%\n",
      "Step:37000, Loss: 2.3057, Accuracy: 10.94%\n",
      "Step:37100, Loss: 2.3025, Accuracy: 10.94%\n",
      "Step:37200, Loss: 2.2943, Accuracy: 15.62%\n",
      "Step:37300, Loss: 2.2989, Accuracy:  9.38%\n",
      "Step:37400, Loss: 2.3035, Accuracy:  7.81%\n",
      "Step:37500, Loss: 2.2994, Accuracy: 10.94%\n",
      "Step:37600, Loss: 2.3043, Accuracy: 10.16%\n",
      "Step:37700, Loss: 2.2985, Accuracy: 15.62%\n",
      "Step:37800, Loss: 2.3043, Accuracy:  9.38%\n",
      "Step:37900, Loss: 2.2997, Accuracy: 10.94%\n",
      "Step:38000, Loss: 2.3014, Accuracy:  8.59%\n",
      "Step:38100, Loss: 2.3003, Accuracy: 11.72%\n",
      "Step:38200, Loss: 2.3032, Accuracy:  8.59%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:38300, Loss: 2.2963, Accuracy: 15.62%\n",
      "Step:38400, Loss: 2.3097, Accuracy:  7.81%\n",
      "Step:38500, Loss: 2.2953, Accuracy: 17.97%\n",
      "Step:38600, Loss: 2.3088, Accuracy:  7.81%\n",
      "Step:38700, Loss: 2.2972, Accuracy: 10.94%\n",
      "Step:38800, Loss: 2.2980, Accuracy: 13.28%\n",
      "Step:38900, Loss: 2.2955, Accuracy: 10.16%\n",
      "Step:39000, Loss: 2.3004, Accuracy: 12.50%\n",
      "Step:39100, Loss: 2.2945, Accuracy: 15.62%\n",
      "Step:39200, Loss: 2.2986, Accuracy: 10.94%\n",
      "Step:39300, Loss: 2.2954, Accuracy: 14.06%\n",
      "Step:39400, Loss: 2.3037, Accuracy: 10.16%\n",
      "Step:39500, Loss: 2.3007, Accuracy: 12.50%\n",
      "Step:39600, Loss: 2.3018, Accuracy: 11.72%\n",
      "Step:39700, Loss: 2.3057, Accuracy:  9.38%\n",
      "Step:39800, Loss: 2.2959, Accuracy: 16.41%\n",
      "Step:39900, Loss: 2.3133, Accuracy:  6.25%\n",
      "Step:40000, Loss: 2.2954, Accuracy: 16.41%\n",
      "Step:40100, Loss: 2.2999, Accuracy: 10.94%\n",
      "Step:40200, Loss: 2.3060, Accuracy:  7.03%\n",
      "Step:40300, Loss: 2.2970, Accuracy: 14.84%\n",
      "Step:40400, Loss: 2.2947, Accuracy: 15.62%\n",
      "Step:40500, Loss: 2.3014, Accuracy: 14.84%\n",
      "Step:40600, Loss: 2.2962, Accuracy: 12.50%\n",
      "Step:40700, Loss: 2.3001, Accuracy: 12.50%\n",
      "Step:40800, Loss: 2.2990, Accuracy: 14.06%\n",
      "Step:40900, Loss: 2.2985, Accuracy: 10.16%\n",
      "Step:41000, Loss: 2.2971, Accuracy: 12.50%\n",
      "Step:41100, Loss: 2.3119, Accuracy:  9.38%\n",
      "Step:41200, Loss: 2.3037, Accuracy: 10.94%\n",
      "Step:41300, Loss: 2.3071, Accuracy:  7.81%\n",
      "Step:41400, Loss: 2.3043, Accuracy: 10.16%\n",
      "Step:41500, Loss: 2.3069, Accuracy:  9.38%\n",
      "Step:41600, Loss: 2.2998, Accuracy: 10.94%\n",
      "Step:41700, Loss: 2.3060, Accuracy:  7.81%\n",
      "Step:41800, Loss: 2.3008, Accuracy: 12.50%\n",
      "Step:41900, Loss: 2.3031, Accuracy:  9.38%\n",
      "Step:42000, Loss: 2.3063, Accuracy:  4.69%\n",
      "Step:42100, Loss: 2.3045, Accuracy: 11.72%\n",
      "Step:42200, Loss: 2.2973, Accuracy: 11.72%\n",
      "Step:42300, Loss: 2.2927, Accuracy: 14.06%\n",
      "Step:42400, Loss: 2.3031, Accuracy: 16.41%\n",
      "Step:42500, Loss: 2.3019, Accuracy: 10.16%\n",
      "Step:42600, Loss: 2.2920, Accuracy: 16.41%\n",
      "Step:42700, Loss: 2.3053, Accuracy: 10.94%\n",
      "Step:42800, Loss: 2.2981, Accuracy: 14.06%\n",
      "Step:42900, Loss: 2.2989, Accuracy:  9.38%\n",
      "Step:43000, Loss: 2.3005, Accuracy: 11.72%\n",
      "Step:43100, Loss: 2.3066, Accuracy:  8.59%\n",
      "Step:43200, Loss: 2.3009, Accuracy: 14.06%\n",
      "Step:43300, Loss: 2.2991, Accuracy: 10.16%\n",
      "Step:43400, Loss: 2.3125, Accuracy:  4.69%\n",
      "Step:43500, Loss: 2.2967, Accuracy: 12.50%\n",
      "Step:43600, Loss: 2.3023, Accuracy: 10.94%\n",
      "Step:43700, Loss: 2.3053, Accuracy: 10.94%\n",
      "Step:43800, Loss: 2.2972, Accuracy: 14.84%\n",
      "Step:43900, Loss: 2.2871, Accuracy: 15.62%\n",
      "Step:44000, Loss: 2.2974, Accuracy: 14.84%\n",
      "Step:44100, Loss: 2.3022, Accuracy: 13.28%\n",
      "Step:44200, Loss: 2.3004, Accuracy: 10.94%\n",
      "Step:44300, Loss: 2.2959, Accuracy: 10.94%\n",
      "Step:44400, Loss: 2.3021, Accuracy: 14.06%\n",
      "Step:44500, Loss: 2.3010, Accuracy: 10.16%\n",
      "Step:44600, Loss: 2.3090, Accuracy:  7.03%\n",
      "Step:44700, Loss: 2.2960, Accuracy: 13.28%\n",
      "Step:44800, Loss: 2.2997, Accuracy: 11.72%\n",
      "Step:44900, Loss: 2.3045, Accuracy: 10.16%\n",
      "Step:45000, Loss: 2.2916, Accuracy: 17.19%\n",
      "Step:45100, Loss: 2.3062, Accuracy:  9.38%\n",
      "Step:45200, Loss: 2.3043, Accuracy: 10.94%\n",
      "Step:45300, Loss: 2.3024, Accuracy: 10.94%\n",
      "Step:45400, Loss: 2.3089, Accuracy:  7.81%\n",
      "Step:45500, Loss: 2.2995, Accuracy: 11.72%\n",
      "Step:45600, Loss: 2.3004, Accuracy: 10.16%\n",
      "Step:45700, Loss: 2.3026, Accuracy: 10.16%\n",
      "Step:45800, Loss: 2.2963, Accuracy: 14.84%\n",
      "Step:45900, Loss: 2.3049, Accuracy: 10.16%\n",
      "Step:46000, Loss: 2.3068, Accuracy:  9.38%\n",
      "Step:46100, Loss: 2.3010, Accuracy: 10.16%\n",
      "Step:46200, Loss: 2.3026, Accuracy: 10.16%\n",
      "Step:46300, Loss: 2.2983, Accuracy: 13.28%\n",
      "Step:46400, Loss: 2.3057, Accuracy:  7.03%\n",
      "Step:46500, Loss: 2.2961, Accuracy: 17.97%\n",
      "Step:46600, Loss: 2.3013, Accuracy: 11.72%\n",
      "Step:46700, Loss: 2.2969, Accuracy: 13.28%\n",
      "Step:46800, Loss: 2.3077, Accuracy:  7.81%\n",
      "Step:46900, Loss: 2.3045, Accuracy: 12.50%\n",
      "Step:47000, Loss: 2.3001, Accuracy: 14.06%\n",
      "Step:47100, Loss: 2.2982, Accuracy: 10.16%\n",
      "Step:47200, Loss: 2.2884, Accuracy: 16.41%\n",
      "Step:47300, Loss: 2.2993, Accuracy:  9.38%\n",
      "Step:47400, Loss: 2.3091, Accuracy:  6.25%\n",
      "Step:47500, Loss: 2.2996, Accuracy: 14.84%\n",
      "Step:47600, Loss: 2.3013, Accuracy: 11.72%\n",
      "Step:47700, Loss: 2.3034, Accuracy:  8.59%\n",
      "Step:47800, Loss: 2.2974, Accuracy: 12.50%\n",
      "Step:47900, Loss: 2.3017, Accuracy:  9.38%\n",
      "Step:48000, Loss: 2.2955, Accuracy: 13.28%\n",
      "Step:48100, Loss: 2.3103, Accuracy:  8.59%\n",
      "Step:48200, Loss: 2.2995, Accuracy: 13.28%\n",
      "Step:48300, Loss: 2.3021, Accuracy: 10.16%\n",
      "Step:48400, Loss: 2.2964, Accuracy: 13.28%\n",
      "Step:48500, Loss: 2.2978, Accuracy: 11.72%\n",
      "Step:48600, Loss: 2.3014, Accuracy: 10.94%\n",
      "Step:48700, Loss: 2.3042, Accuracy: 12.50%\n",
      "Step:48800, Loss: 2.2986, Accuracy: 12.50%\n",
      "Step:48900, Loss: 2.3004, Accuracy: 12.50%\n",
      "Step:49000, Loss: 2.2961, Accuracy: 14.84%\n",
      "Step:49100, Loss: 2.2969, Accuracy:  9.38%\n",
      "Step:49200, Loss: 2.3015, Accuracy: 10.16%\n",
      "Step:49300, Loss: 2.3074, Accuracy:  7.03%\n",
      "Step:49400, Loss: 2.2971, Accuracy: 13.28%\n",
      "Step:49500, Loss: 2.2988, Accuracy: 12.50%\n",
      "Step:49600, Loss: 2.3051, Accuracy:  7.81%\n",
      "Step:49700, Loss: 2.3012, Accuracy: 12.50%\n",
      "Step:49800, Loss: 2.2951, Accuracy: 14.84%\n",
      "Step:49900, Loss: 2.2906, Accuracy: 17.19%\n",
      "Training Finished, Loss: 2.3011, Accuracy: 11.35%\n"
     ]
    }
   ],
   "source": [
    "for i in range(50000):\n",
    "    batch = mnist.train.next_batch(128)\n",
    "    _, loss_, acu = sess.run([train_step, loss, accuracy], {x: batch[0], y_: batch[1]})\n",
    "    if i % 100 == 0:\n",
    "        print(\"Step:{:>5}, Loss:{:>7.4f}, Accuracy:{:>7.2%}\".format(i, loss_, acu))\n",
    "loss_, acu = sess.run([loss, accuracy], {x: mnist.test.images, \n",
    "                                        y_: mnist.test.labels})\n",
    "print(\"Training Finished, Loss:{:>7.4f}, Accuracy:{:>7.2%}\".format(loss_, acu))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# tan 练习\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1 = tf.layers.dense(inputs=x, \n",
    "                         units=20, \n",
    "                         activation=tf.nn.tanh,                        \n",
    "                         bias_initializer=tf.constant_initializer(0),\n",
    "                         kernel_initializer=tf.truncated_normal_initializer(stddev=0.1)\n",
    "                        )\n",
    "layer2 = tf.layers.dense(inputs=layer1, \n",
    "                         units=20, \n",
    "                         activation=tf.nn.tanh,                        \n",
    "                         bias_initializer=tf.constant_initializer(0),\n",
    "                         kernel_initializer=tf.truncated_normal_initializer(stddev=0.1)\n",
    "                        )\n",
    "layer3 = tf.layers.dense(inputs=layer2, \n",
    "                         units=20, \n",
    "                         activation=tf.nn.tanh,                        \n",
    "                         bias_initializer=tf.constant_initializer(0),\n",
    "                         kernel_initializer=tf.truncated_normal_initializer(stddev=0.1)\n",
    "                        )\n",
    "layer4 = tf.layers.dense(inputs=layer3, \n",
    "                         units=20, \n",
    "                         activation=tf.nn.tanh,                        \n",
    "                         bias_initializer=tf.constant_initializer(0),\n",
    "                         kernel_initializer=tf.truncated_normal_initializer(stddev=0.1)\n",
    "                        )\n",
    "layer5 = tf.layers.dense(inputs=layer4, \n",
    "                         units=20, \n",
    "                         activation=tf.nn.tanh,                        \n",
    "                         bias_initializer=tf.constant_initializer(0),\n",
    "                         kernel_initializer=tf.truncated_normal_initializer(stddev=0.1)\n",
    "                        )\n",
    "layer6 = tf.layers.dense(inputs=layer5, \n",
    "                         units=20, \n",
    "                         activation=tf.nn.tanh,                        \n",
    "                         bias_initializer=tf.constant_initializer(0),\n",
    "                         kernel_initializer=tf.truncated_normal_initializer(stddev=0.1)\n",
    "                        )\n",
    "y = tf.layers.dense(inputs=layer6, \n",
    "                    units=10, \n",
    "                    activation=None, \n",
    "                    bias_initializer=tf.constant_initializer(0), \n",
    "                    kernel_initializer=tf.truncated_normal_initializer(stddev=0.1)\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:    0, Loss: 2.3026, Accuracy:  7.81%\n",
      "Step:  100, Loss: 2.3017, Accuracy: 12.50%\n",
      "Step:  200, Loss: 2.3025, Accuracy: 10.94%\n",
      "Step:  300, Loss: 2.3025, Accuracy: 10.16%\n",
      "Step:  400, Loss: 2.3044, Accuracy:  8.59%\n",
      "Step:  500, Loss: 2.3038, Accuracy:  9.38%\n",
      "Step:  600, Loss: 2.3026, Accuracy:  8.59%\n",
      "Step:  700, Loss: 2.2989, Accuracy: 15.62%\n",
      "Step:  800, Loss: 2.3030, Accuracy:  8.59%\n",
      "Step:  900, Loss: 2.3044, Accuracy:  7.81%\n",
      "Step: 1000, Loss: 2.3015, Accuracy: 10.94%\n",
      "Step: 1100, Loss: 2.2978, Accuracy: 14.84%\n",
      "Step: 1200, Loss: 2.3039, Accuracy:  7.81%\n",
      "Step: 1300, Loss: 2.2974, Accuracy: 16.41%\n",
      "Step: 1400, Loss: 2.3008, Accuracy:  7.03%\n",
      "Step: 1500, Loss: 2.3014, Accuracy: 11.72%\n",
      "Step: 1600, Loss: 2.2975, Accuracy: 11.72%\n",
      "Step: 1700, Loss: 2.2988, Accuracy: 12.50%\n",
      "Step: 1800, Loss: 2.2991, Accuracy: 10.16%\n",
      "Step: 1900, Loss: 2.2980, Accuracy: 12.50%\n",
      "Step: 2000, Loss: 2.2985, Accuracy: 12.50%\n",
      "Step: 2100, Loss: 2.3048, Accuracy: 10.16%\n",
      "Step: 2200, Loss: 2.3120, Accuracy:  4.69%\n",
      "Step: 2300, Loss: 2.3005, Accuracy: 14.06%\n",
      "Step: 2400, Loss: 2.3039, Accuracy: 11.72%\n",
      "Step: 2500, Loss: 2.2983, Accuracy: 13.28%\n",
      "Step: 2600, Loss: 2.2968, Accuracy: 12.50%\n",
      "Step: 2700, Loss: 2.3115, Accuracy:  7.03%\n",
      "Step: 2800, Loss: 2.2986, Accuracy: 12.50%\n",
      "Step: 2900, Loss: 2.3042, Accuracy:  6.25%\n",
      "Step: 3000, Loss: 2.2989, Accuracy: 10.94%\n",
      "Step: 3100, Loss: 2.2935, Accuracy: 15.62%\n",
      "Step: 3200, Loss: 2.3016, Accuracy:  9.38%\n",
      "Step: 3300, Loss: 2.2947, Accuracy: 14.06%\n",
      "Step: 3400, Loss: 2.3063, Accuracy:  7.81%\n",
      "Step: 3500, Loss: 2.3065, Accuracy:  7.81%\n",
      "Step: 3600, Loss: 2.3033, Accuracy: 10.94%\n",
      "Step: 3700, Loss: 2.3076, Accuracy: 10.16%\n",
      "Step: 3800, Loss: 2.2955, Accuracy: 14.06%\n",
      "Step: 3900, Loss: 2.3051, Accuracy:  7.03%\n",
      "Step: 4000, Loss: 2.2974, Accuracy: 13.28%\n",
      "Step: 4100, Loss: 2.2954, Accuracy: 15.62%\n",
      "Step: 4200, Loss: 2.3041, Accuracy: 10.16%\n",
      "Step: 4300, Loss: 2.3024, Accuracy: 10.94%\n",
      "Step: 4400, Loss: 2.2934, Accuracy: 14.06%\n",
      "Step: 4500, Loss: 2.3067, Accuracy: 10.16%\n",
      "Step: 4600, Loss: 2.3074, Accuracy:  9.38%\n",
      "Step: 4700, Loss: 2.3012, Accuracy:  9.38%\n",
      "Step: 4800, Loss: 2.3007, Accuracy: 14.06%\n",
      "Step: 4900, Loss: 2.3027, Accuracy:  9.38%\n",
      "Step: 5000, Loss: 2.3044, Accuracy: 10.16%\n",
      "Step: 5100, Loss: 2.2982, Accuracy: 11.72%\n",
      "Step: 5200, Loss: 2.2964, Accuracy:  9.38%\n",
      "Step: 5300, Loss: 2.2946, Accuracy: 14.06%\n",
      "Step: 5400, Loss: 2.2979, Accuracy: 10.16%\n",
      "Step: 5500, Loss: 2.2980, Accuracy: 14.06%\n",
      "Step: 5600, Loss: 2.2992, Accuracy:  7.03%\n",
      "Step: 5700, Loss: 2.2971, Accuracy: 12.50%\n",
      "Step: 5800, Loss: 2.2915, Accuracy: 13.28%\n",
      "Step: 5900, Loss: 2.2970, Accuracy: 11.72%\n",
      "Step: 6000, Loss: 2.2970, Accuracy:  9.38%\n",
      "Step: 6100, Loss: 2.2897, Accuracy: 10.16%\n",
      "Step: 6200, Loss: 2.2934, Accuracy: 10.94%\n",
      "Step: 6300, Loss: 2.2936, Accuracy:  8.59%\n",
      "Step: 6400, Loss: 2.2901, Accuracy: 10.16%\n",
      "Step: 6500, Loss: 2.2800, Accuracy: 11.72%\n",
      "Step: 6600, Loss: 2.2865, Accuracy:  7.81%\n",
      "Step: 6700, Loss: 2.2741, Accuracy: 15.62%\n",
      "Step: 6800, Loss: 2.2632, Accuracy: 21.88%\n",
      "Step: 6900, Loss: 2.2262, Accuracy: 39.84%\n",
      "Step: 7000, Loss: 2.2077, Accuracy: 26.56%\n",
      "Step: 7100, Loss: 2.1341, Accuracy: 31.25%\n",
      "Step: 7200, Loss: 2.0450, Accuracy: 27.34%\n",
      "Step: 7300, Loss: 1.9749, Accuracy: 25.00%\n",
      "Step: 7400, Loss: 1.8952, Accuracy: 28.12%\n",
      "Step: 7500, Loss: 1.8555, Accuracy: 25.00%\n",
      "Step: 7600, Loss: 1.8686, Accuracy: 23.44%\n",
      "Step: 7700, Loss: 1.8010, Accuracy: 24.22%\n",
      "Step: 7800, Loss: 1.8319, Accuracy: 18.75%\n",
      "Step: 7900, Loss: 1.8803, Accuracy: 28.91%\n",
      "Step: 8000, Loss: 1.7711, Accuracy: 24.22%\n",
      "Step: 8100, Loss: 1.7650, Accuracy: 24.22%\n",
      "Step: 8200, Loss: 1.6874, Accuracy: 27.34%\n",
      "Step: 8300, Loss: 1.7208, Accuracy: 28.12%\n",
      "Step: 8400, Loss: 1.7035, Accuracy: 28.12%\n",
      "Step: 8500, Loss: 1.7220, Accuracy: 29.69%\n",
      "Step: 8600, Loss: 1.6948, Accuracy: 35.16%\n",
      "Step: 8700, Loss: 1.8028, Accuracy: 33.59%\n",
      "Step: 8800, Loss: 1.7151, Accuracy: 36.72%\n",
      "Step: 8900, Loss: 1.7027, Accuracy: 32.81%\n",
      "Step: 9000, Loss: 1.6430, Accuracy: 34.38%\n",
      "Step: 9100, Loss: 1.6363, Accuracy: 42.97%\n",
      "Step: 9200, Loss: 1.5941, Accuracy: 35.16%\n",
      "Step: 9300, Loss: 1.6845, Accuracy: 35.94%\n",
      "Step: 9400, Loss: 1.5203, Accuracy: 57.03%\n",
      "Step: 9500, Loss: 1.5357, Accuracy: 48.44%\n",
      "Step: 9600, Loss: 1.4160, Accuracy: 50.78%\n",
      "Step: 9700, Loss: 1.4665, Accuracy: 39.84%\n",
      "Step: 9800, Loss: 1.3481, Accuracy: 54.69%\n",
      "Step: 9900, Loss: 1.4022, Accuracy: 42.19%\n",
      "Step:10000, Loss: 1.2214, Accuracy: 54.69%\n",
      "Step:10100, Loss: 1.2200, Accuracy: 48.44%\n",
      "Step:10200, Loss: 1.2070, Accuracy: 63.28%\n",
      "Step:10300, Loss: 1.1599, Accuracy: 62.50%\n",
      "Step:10400, Loss: 1.2165, Accuracy: 54.69%\n",
      "Step:10500, Loss: 1.1209, Accuracy: 55.47%\n",
      "Step:10600, Loss: 1.2058, Accuracy: 58.59%\n",
      "Step:10700, Loss: 1.1176, Accuracy: 60.16%\n",
      "Step:10800, Loss: 1.1288, Accuracy: 61.72%\n",
      "Step:10900, Loss: 1.0776, Accuracy: 58.59%\n",
      "Step:11000, Loss: 1.0722, Accuracy: 62.50%\n",
      "Step:11100, Loss: 1.1395, Accuracy: 61.72%\n",
      "Step:11200, Loss: 1.1676, Accuracy: 56.25%\n",
      "Step:11300, Loss: 1.0431, Accuracy: 66.41%\n",
      "Step:11400, Loss: 0.9129, Accuracy: 64.06%\n",
      "Step:11500, Loss: 1.0736, Accuracy: 62.50%\n",
      "Step:11600, Loss: 1.0963, Accuracy: 60.16%\n",
      "Step:11700, Loss: 1.0013, Accuracy: 66.41%\n",
      "Step:11800, Loss: 0.9618, Accuracy: 69.53%\n",
      "Step:11900, Loss: 0.8509, Accuracy: 73.44%\n",
      "Step:12000, Loss: 0.9269, Accuracy: 71.09%\n",
      "Step:12100, Loss: 0.9665, Accuracy: 65.62%\n",
      "Step:12200, Loss: 0.9048, Accuracy: 74.22%\n",
      "Step:12300, Loss: 0.8534, Accuracy: 71.09%\n",
      "Step:12400, Loss: 0.9074, Accuracy: 75.00%\n",
      "Step:12500, Loss: 0.8291, Accuracy: 79.69%\n",
      "Step:12600, Loss: 0.8323, Accuracy: 76.56%\n",
      "Step:12700, Loss: 0.7920, Accuracy: 76.56%\n",
      "Step:12800, Loss: 0.8357, Accuracy: 77.34%\n",
      "Step:12900, Loss: 0.7538, Accuracy: 72.66%\n",
      "Step:13000, Loss: 0.8183, Accuracy: 70.31%\n",
      "Step:13100, Loss: 0.7353, Accuracy: 78.91%\n",
      "Step:13200, Loss: 0.7021, Accuracy: 80.47%\n",
      "Step:13300, Loss: 0.7333, Accuracy: 82.81%\n",
      "Step:13400, Loss: 0.7988, Accuracy: 79.69%\n",
      "Step:13500, Loss: 0.7700, Accuracy: 75.00%\n",
      "Step:13600, Loss: 0.8180, Accuracy: 80.47%\n",
      "Step:13700, Loss: 0.6134, Accuracy: 81.25%\n",
      "Step:13800, Loss: 0.7122, Accuracy: 85.94%\n",
      "Step:13900, Loss: 0.7771, Accuracy: 83.59%\n",
      "Step:14000, Loss: 0.7397, Accuracy: 79.69%\n",
      "Step:14100, Loss: 0.6047, Accuracy: 83.59%\n",
      "Step:14200, Loss: 0.5713, Accuracy: 80.47%\n",
      "Step:14300, Loss: 0.5788, Accuracy: 84.38%\n",
      "Step:14400, Loss: 0.5842, Accuracy: 86.72%\n",
      "Step:14500, Loss: 0.5580, Accuracy: 85.94%\n",
      "Step:14600, Loss: 0.7121, Accuracy: 82.81%\n",
      "Step:14700, Loss: 0.4952, Accuracy: 93.75%\n",
      "Step:14800, Loss: 0.4274, Accuracy: 87.50%\n",
      "Step:14900, Loss: 0.5184, Accuracy: 90.62%\n",
      "Step:15000, Loss: 0.4589, Accuracy: 86.72%\n",
      "Step:15100, Loss: 0.3656, Accuracy: 92.19%\n",
      "Step:15200, Loss: 0.4968, Accuracy: 89.84%\n",
      "Step:15300, Loss: 0.6197, Accuracy: 86.72%\n",
      "Step:15400, Loss: 0.5916, Accuracy: 86.72%\n",
      "Step:15500, Loss: 0.6203, Accuracy: 86.72%\n",
      "Step:15600, Loss: 0.4668, Accuracy: 87.50%\n",
      "Step:15700, Loss: 0.5365, Accuracy: 86.72%\n",
      "Step:15800, Loss: 0.5194, Accuracy: 87.50%\n",
      "Step:15900, Loss: 0.5194, Accuracy: 85.94%\n",
      "Step:16000, Loss: 0.6540, Accuracy: 86.72%\n",
      "Step:16100, Loss: 0.5467, Accuracy: 82.81%\n",
      "Step:16200, Loss: 0.5881, Accuracy: 84.38%\n",
      "Step:16300, Loss: 0.4831, Accuracy: 88.28%\n",
      "Step:16400, Loss: 0.4623, Accuracy: 85.16%\n",
      "Step:16500, Loss: 0.4004, Accuracy: 90.62%\n",
      "Step:16600, Loss: 0.3582, Accuracy: 90.62%\n",
      "Step:16700, Loss: 0.3098, Accuracy: 91.41%\n",
      "Step:16800, Loss: 0.4590, Accuracy: 91.41%\n",
      "Step:16900, Loss: 0.4145, Accuracy: 85.16%\n",
      "Step:17000, Loss: 0.3540, Accuracy: 92.97%\n",
      "Step:17100, Loss: 0.4072, Accuracy: 92.97%\n",
      "Step:17200, Loss: 0.4612, Accuracy: 88.28%\n",
      "Step:17300, Loss: 0.4867, Accuracy: 85.94%\n",
      "Step:17400, Loss: 0.3630, Accuracy: 89.06%\n",
      "Step:17500, Loss: 0.2846, Accuracy: 93.75%\n",
      "Step:17600, Loss: 0.3475, Accuracy: 92.97%\n",
      "Step:17700, Loss: 0.4648, Accuracy: 92.19%\n",
      "Step:17800, Loss: 0.4009, Accuracy: 86.72%\n",
      "Step:17900, Loss: 0.3741, Accuracy: 89.06%\n",
      "Step:18000, Loss: 0.4302, Accuracy: 89.06%\n",
      "Step:18100, Loss: 0.3997, Accuracy: 92.97%\n",
      "Step:18200, Loss: 0.3611, Accuracy: 92.97%\n",
      "Step:18300, Loss: 0.4607, Accuracy: 88.28%\n",
      "Step:18400, Loss: 0.6179, Accuracy: 84.38%\n",
      "Step:18500, Loss: 0.3605, Accuracy: 91.41%\n",
      "Step:18600, Loss: 0.3803, Accuracy: 90.62%\n",
      "Step:18700, Loss: 0.3327, Accuracy: 90.62%\n",
      "Step:18800, Loss: 0.6098, Accuracy: 89.84%\n",
      "Step:18900, Loss: 0.3322, Accuracy: 92.19%\n",
      "Step:19000, Loss: 0.4365, Accuracy: 92.97%\n",
      "Step:19100, Loss: 0.3332, Accuracy: 92.97%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:19200, Loss: 0.2873, Accuracy: 90.62%\n",
      "Step:19300, Loss: 0.4035, Accuracy: 89.06%\n",
      "Step:19400, Loss: 0.5546, Accuracy: 86.72%\n",
      "Step:19500, Loss: 0.2756, Accuracy: 96.09%\n",
      "Step:19600, Loss: 0.3091, Accuracy: 92.19%\n",
      "Step:19700, Loss: 0.4190, Accuracy: 89.84%\n",
      "Step:19800, Loss: 0.3808, Accuracy: 89.84%\n",
      "Step:19900, Loss: 0.2550, Accuracy: 92.97%\n",
      "Step:20000, Loss: 0.2724, Accuracy: 92.97%\n",
      "Step:20100, Loss: 0.3309, Accuracy: 87.50%\n",
      "Step:20200, Loss: 0.4593, Accuracy: 89.06%\n",
      "Step:20300, Loss: 0.3836, Accuracy: 89.84%\n",
      "Step:20400, Loss: 0.4558, Accuracy: 89.06%\n",
      "Step:20500, Loss: 0.2823, Accuracy: 94.53%\n",
      "Step:20600, Loss: 0.4486, Accuracy: 88.28%\n",
      "Step:20700, Loss: 0.3180, Accuracy: 92.19%\n",
      "Step:20800, Loss: 0.6061, Accuracy: 84.38%\n",
      "Step:20900, Loss: 0.3630, Accuracy: 92.19%\n",
      "Step:21000, Loss: 0.4063, Accuracy: 91.41%\n",
      "Step:21100, Loss: 0.1931, Accuracy: 94.53%\n",
      "Step:21200, Loss: 0.3335, Accuracy: 89.84%\n",
      "Step:21300, Loss: 0.2809, Accuracy: 93.75%\n",
      "Step:21400, Loss: 0.3984, Accuracy: 90.62%\n",
      "Step:21500, Loss: 0.3008, Accuracy: 92.97%\n",
      "Step:21600, Loss: 0.2587, Accuracy: 96.09%\n",
      "Step:21700, Loss: 0.3552, Accuracy: 91.41%\n",
      "Step:21800, Loss: 0.3811, Accuracy: 91.41%\n",
      "Step:21900, Loss: 0.2608, Accuracy: 92.19%\n",
      "Step:22000, Loss: 0.3788, Accuracy: 89.06%\n",
      "Step:22100, Loss: 0.3599, Accuracy: 90.62%\n",
      "Step:22200, Loss: 0.2987, Accuracy: 91.41%\n",
      "Step:22300, Loss: 0.2844, Accuracy: 92.19%\n",
      "Step:22400, Loss: 0.4274, Accuracy: 87.50%\n",
      "Step:22500, Loss: 0.1985, Accuracy: 93.75%\n",
      "Step:22600, Loss: 0.2473, Accuracy: 92.19%\n",
      "Step:22700, Loss: 0.2243, Accuracy: 96.09%\n",
      "Step:22800, Loss: 0.3470, Accuracy: 90.62%\n",
      "Step:22900, Loss: 0.3427, Accuracy: 91.41%\n",
      "Step:23000, Loss: 0.2101, Accuracy: 96.88%\n",
      "Step:23100, Loss: 0.3805, Accuracy: 89.84%\n",
      "Step:23200, Loss: 0.3171, Accuracy: 92.97%\n",
      "Step:23300, Loss: 0.2132, Accuracy: 96.09%\n",
      "Step:23400, Loss: 0.2528, Accuracy: 94.53%\n",
      "Step:23500, Loss: 0.2453, Accuracy: 94.53%\n",
      "Step:23600, Loss: 0.2289, Accuracy: 93.75%\n",
      "Step:23700, Loss: 0.1700, Accuracy: 94.53%\n",
      "Step:23800, Loss: 0.2020, Accuracy: 92.97%\n",
      "Step:23900, Loss: 0.4511, Accuracy: 91.41%\n",
      "Step:24000, Loss: 0.3203, Accuracy: 91.41%\n",
      "Step:24100, Loss: 0.3637, Accuracy: 89.84%\n",
      "Step:24200, Loss: 0.2857, Accuracy: 92.19%\n",
      "Step:24300, Loss: 0.2522, Accuracy: 93.75%\n",
      "Step:24400, Loss: 0.3982, Accuracy: 90.62%\n",
      "Step:24500, Loss: 0.2113, Accuracy: 94.53%\n",
      "Step:24600, Loss: 0.3116, Accuracy: 92.97%\n",
      "Step:24700, Loss: 0.2624, Accuracy: 92.19%\n",
      "Step:24800, Loss: 0.3653, Accuracy: 89.06%\n",
      "Step:24900, Loss: 0.3634, Accuracy: 93.75%\n",
      "Step:25000, Loss: 0.3800, Accuracy: 91.41%\n",
      "Step:25100, Loss: 0.4288, Accuracy: 93.75%\n",
      "Step:25200, Loss: 0.2498, Accuracy: 93.75%\n",
      "Step:25300, Loss: 0.3512, Accuracy: 89.06%\n",
      "Step:25400, Loss: 0.2874, Accuracy: 92.19%\n",
      "Step:25500, Loss: 0.4063, Accuracy: 89.06%\n",
      "Step:25600, Loss: 0.3180, Accuracy: 89.06%\n",
      "Step:25700, Loss: 0.2874, Accuracy: 90.62%\n",
      "Step:25800, Loss: 0.2680, Accuracy: 92.97%\n",
      "Step:25900, Loss: 0.4103, Accuracy: 90.62%\n",
      "Step:26000, Loss: 0.2665, Accuracy: 94.53%\n",
      "Step:26100, Loss: 0.2086, Accuracy: 92.97%\n",
      "Step:26200, Loss: 0.2831, Accuracy: 90.62%\n",
      "Step:26300, Loss: 0.4106, Accuracy: 89.84%\n",
      "Step:26400, Loss: 0.2185, Accuracy: 93.75%\n",
      "Step:26500, Loss: 0.2058, Accuracy: 94.53%\n",
      "Step:26600, Loss: 0.2839, Accuracy: 96.09%\n",
      "Step:26700, Loss: 0.2553, Accuracy: 94.53%\n",
      "Step:26800, Loss: 0.2535, Accuracy: 93.75%\n",
      "Step:26900, Loss: 0.2182, Accuracy: 92.97%\n",
      "Step:27000, Loss: 0.3849, Accuracy: 91.41%\n",
      "Step:27100, Loss: 0.2388, Accuracy: 91.41%\n",
      "Step:27200, Loss: 0.3563, Accuracy: 91.41%\n",
      "Step:27300, Loss: 0.2306, Accuracy: 92.19%\n",
      "Step:27400, Loss: 0.2716, Accuracy: 94.53%\n",
      "Step:27500, Loss: 0.1475, Accuracy: 96.09%\n",
      "Step:27600, Loss: 0.2183, Accuracy: 96.09%\n",
      "Step:27700, Loss: 0.5519, Accuracy: 90.62%\n",
      "Step:27800, Loss: 0.1361, Accuracy: 97.66%\n",
      "Step:27900, Loss: 0.1656, Accuracy: 96.88%\n",
      "Step:28000, Loss: 0.1818, Accuracy: 96.09%\n",
      "Step:28100, Loss: 0.2874, Accuracy: 94.53%\n",
      "Step:28200, Loss: 0.3032, Accuracy: 92.19%\n",
      "Step:28300, Loss: 0.2070, Accuracy: 95.31%\n",
      "Step:28400, Loss: 0.2805, Accuracy: 92.97%\n",
      "Step:28500, Loss: 0.2190, Accuracy: 96.09%\n",
      "Step:28600, Loss: 0.2403, Accuracy: 92.97%\n",
      "Step:28700, Loss: 0.2197, Accuracy: 93.75%\n",
      "Step:28800, Loss: 0.2724, Accuracy: 92.19%\n",
      "Step:28900, Loss: 0.1967, Accuracy: 96.09%\n",
      "Step:29000, Loss: 0.3249, Accuracy: 93.75%\n",
      "Step:29100, Loss: 0.2328, Accuracy: 91.41%\n",
      "Step:29200, Loss: 0.2396, Accuracy: 92.19%\n",
      "Step:29300, Loss: 0.3137, Accuracy: 92.19%\n",
      "Step:29400, Loss: 0.1908, Accuracy: 96.09%\n",
      "Step:29500, Loss: 0.2011, Accuracy: 95.31%\n",
      "Step:29600, Loss: 0.2049, Accuracy: 97.66%\n",
      "Step:29700, Loss: 0.1708, Accuracy: 95.31%\n",
      "Step:29800, Loss: 0.1583, Accuracy: 94.53%\n",
      "Step:29900, Loss: 0.2493, Accuracy: 92.97%\n",
      "Step:30000, Loss: 0.2365, Accuracy: 95.31%\n",
      "Step:30100, Loss: 0.1560, Accuracy: 95.31%\n",
      "Step:30200, Loss: 0.3019, Accuracy: 92.97%\n",
      "Step:30300, Loss: 0.1602, Accuracy: 97.66%\n",
      "Step:30400, Loss: 0.1588, Accuracy: 96.88%\n",
      "Step:30500, Loss: 0.2207, Accuracy: 96.09%\n",
      "Step:30600, Loss: 0.2444, Accuracy: 95.31%\n",
      "Step:30700, Loss: 0.1308, Accuracy: 97.66%\n",
      "Step:30800, Loss: 0.1046, Accuracy: 97.66%\n",
      "Step:30900, Loss: 0.2054, Accuracy: 94.53%\n",
      "Step:31000, Loss: 0.3217, Accuracy: 92.97%\n",
      "Step:31100, Loss: 0.2461, Accuracy: 93.75%\n",
      "Step:31200, Loss: 0.2748, Accuracy: 92.97%\n",
      "Step:31300, Loss: 0.1941, Accuracy: 93.75%\n",
      "Step:31400, Loss: 0.1671, Accuracy: 96.09%\n",
      "Step:31500, Loss: 0.2031, Accuracy: 95.31%\n",
      "Step:31600, Loss: 0.2033, Accuracy: 93.75%\n",
      "Step:31700, Loss: 0.1789, Accuracy: 93.75%\n",
      "Step:31800, Loss: 0.3537, Accuracy: 92.19%\n",
      "Step:31900, Loss: 0.1578, Accuracy: 95.31%\n",
      "Step:32000, Loss: 0.1309, Accuracy: 96.88%\n",
      "Step:32100, Loss: 0.2864, Accuracy: 92.97%\n",
      "Step:32200, Loss: 0.1426, Accuracy: 98.44%\n",
      "Step:32300, Loss: 0.1208, Accuracy: 96.88%\n",
      "Step:32400, Loss: 0.3634, Accuracy: 93.75%\n",
      "Step:32500, Loss: 0.3145, Accuracy: 92.97%\n",
      "Step:32600, Loss: 0.2608, Accuracy: 92.97%\n",
      "Step:32700, Loss: 0.1858, Accuracy: 94.53%\n",
      "Step:32800, Loss: 0.2323, Accuracy: 94.53%\n",
      "Step:32900, Loss: 0.1440, Accuracy: 96.88%\n",
      "Step:33000, Loss: 0.3021, Accuracy: 92.97%\n",
      "Step:33100, Loss: 0.2391, Accuracy: 91.41%\n",
      "Step:33200, Loss: 0.1190, Accuracy: 97.66%\n",
      "Step:33300, Loss: 0.1489, Accuracy: 95.31%\n",
      "Step:33400, Loss: 0.3138, Accuracy: 94.53%\n",
      "Step:33500, Loss: 0.1910, Accuracy: 95.31%\n",
      "Step:33600, Loss: 0.1610, Accuracy: 93.75%\n",
      "Step:33700, Loss: 0.1304, Accuracy: 97.66%\n",
      "Step:33800, Loss: 0.1096, Accuracy: 97.66%\n",
      "Step:33900, Loss: 0.1985, Accuracy: 93.75%\n",
      "Step:34000, Loss: 0.1807, Accuracy: 96.88%\n",
      "Step:34100, Loss: 0.0917, Accuracy: 96.09%\n",
      "Step:34200, Loss: 0.1462, Accuracy: 94.53%\n",
      "Step:34300, Loss: 0.1652, Accuracy: 95.31%\n",
      "Step:34400, Loss: 0.1068, Accuracy: 96.88%\n",
      "Step:34500, Loss: 0.1192, Accuracy: 97.66%\n",
      "Step:34600, Loss: 0.2006, Accuracy: 94.53%\n",
      "Step:34700, Loss: 0.2824, Accuracy: 96.09%\n",
      "Step:34800, Loss: 0.1462, Accuracy: 95.31%\n",
      "Step:34900, Loss: 0.2674, Accuracy: 94.53%\n",
      "Step:35000, Loss: 0.0916, Accuracy: 97.66%\n",
      "Step:35100, Loss: 0.2020, Accuracy: 93.75%\n",
      "Step:35200, Loss: 0.3665, Accuracy: 91.41%\n",
      "Step:35300, Loss: 0.1126, Accuracy: 97.66%\n",
      "Step:35400, Loss: 0.1786, Accuracy: 96.88%\n",
      "Step:35500, Loss: 0.1181, Accuracy: 96.09%\n",
      "Step:35600, Loss: 0.1732, Accuracy: 95.31%\n",
      "Step:35700, Loss: 0.2172, Accuracy: 93.75%\n",
      "Step:35800, Loss: 0.2077, Accuracy: 94.53%\n",
      "Step:35900, Loss: 0.1652, Accuracy: 96.88%\n",
      "Step:36000, Loss: 0.1419, Accuracy: 94.53%\n",
      "Step:36100, Loss: 0.2487, Accuracy: 93.75%\n",
      "Step:36200, Loss: 0.1582, Accuracy: 95.31%\n",
      "Step:36300, Loss: 0.2446, Accuracy: 94.53%\n",
      "Step:36400, Loss: 0.1380, Accuracy: 96.88%\n",
      "Step:36500, Loss: 0.1439, Accuracy: 96.09%\n",
      "Step:36600, Loss: 0.1928, Accuracy: 95.31%\n",
      "Step:36700, Loss: 0.1331, Accuracy: 96.88%\n",
      "Step:36800, Loss: 0.2400, Accuracy: 94.53%\n",
      "Step:36900, Loss: 0.1498, Accuracy: 94.53%\n",
      "Step:37000, Loss: 0.1148, Accuracy: 96.88%\n",
      "Step:37100, Loss: 0.1557, Accuracy: 95.31%\n",
      "Step:37200, Loss: 0.2287, Accuracy: 93.75%\n",
      "Step:37300, Loss: 0.1235, Accuracy: 97.66%\n",
      "Step:37400, Loss: 0.2703, Accuracy: 93.75%\n",
      "Step:37500, Loss: 0.1430, Accuracy: 96.88%\n",
      "Step:37600, Loss: 0.1508, Accuracy: 98.44%\n",
      "Step:37700, Loss: 0.2807, Accuracy: 92.97%\n",
      "Step:37800, Loss: 0.1839, Accuracy: 94.53%\n",
      "Step:37900, Loss: 0.1299, Accuracy: 95.31%\n",
      "Step:38000, Loss: 0.1136, Accuracy: 97.66%\n",
      "Step:38100, Loss: 0.1796, Accuracy: 92.97%\n",
      "Step:38200, Loss: 0.1932, Accuracy: 94.53%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:38300, Loss: 0.1381, Accuracy: 96.88%\n",
      "Step:38400, Loss: 0.2040, Accuracy: 94.53%\n",
      "Step:38500, Loss: 0.0920, Accuracy: 97.66%\n",
      "Step:38600, Loss: 0.2414, Accuracy: 91.41%\n",
      "Step:38700, Loss: 0.1196, Accuracy: 95.31%\n",
      "Step:38800, Loss: 0.0776, Accuracy: 99.22%\n",
      "Step:38900, Loss: 0.0871, Accuracy: 97.66%\n",
      "Step:39000, Loss: 0.2556, Accuracy: 93.75%\n",
      "Step:39100, Loss: 0.1652, Accuracy: 94.53%\n",
      "Step:39200, Loss: 0.2030, Accuracy: 96.09%\n",
      "Step:39300, Loss: 0.1747, Accuracy: 95.31%\n",
      "Step:39400, Loss: 0.1116, Accuracy: 96.09%\n",
      "Step:39500, Loss: 0.1062, Accuracy: 97.66%\n",
      "Step:39600, Loss: 0.1791, Accuracy: 92.97%\n",
      "Step:39700, Loss: 0.1450, Accuracy: 96.09%\n",
      "Step:39800, Loss: 0.1503, Accuracy: 93.75%\n",
      "Step:39900, Loss: 0.2204, Accuracy: 94.53%\n",
      "Step:40000, Loss: 0.1750, Accuracy: 95.31%\n",
      "Step:40100, Loss: 0.0918, Accuracy: 96.88%\n",
      "Step:40200, Loss: 0.2326, Accuracy: 92.19%\n",
      "Step:40300, Loss: 0.1914, Accuracy: 92.97%\n",
      "Step:40400, Loss: 0.2331, Accuracy: 95.31%\n",
      "Step:40500, Loss: 0.1602, Accuracy: 96.88%\n",
      "Step:40600, Loss: 0.1116, Accuracy: 96.88%\n",
      "Step:40700, Loss: 0.2113, Accuracy: 95.31%\n",
      "Step:40800, Loss: 0.1650, Accuracy: 93.75%\n",
      "Step:40900, Loss: 0.3505, Accuracy: 94.53%\n",
      "Step:41000, Loss: 0.1536, Accuracy: 94.53%\n",
      "Step:41100, Loss: 0.2460, Accuracy: 94.53%\n",
      "Step:41200, Loss: 0.1708, Accuracy: 96.88%\n",
      "Step:41300, Loss: 0.0884, Accuracy: 97.66%\n",
      "Step:41400, Loss: 0.1411, Accuracy: 97.66%\n",
      "Step:41500, Loss: 0.1505, Accuracy: 95.31%\n",
      "Step:41600, Loss: 0.1571, Accuracy: 96.09%\n",
      "Step:41700, Loss: 0.2588, Accuracy: 92.97%\n",
      "Step:41800, Loss: 0.0382, Accuracy:100.00%\n",
      "Step:41900, Loss: 0.1670, Accuracy: 96.09%\n",
      "Step:42000, Loss: 0.2276, Accuracy: 96.09%\n",
      "Step:42100, Loss: 0.2065, Accuracy: 93.75%\n",
      "Step:42200, Loss: 0.2422, Accuracy: 96.09%\n",
      "Step:42300, Loss: 0.3032, Accuracy: 93.75%\n",
      "Step:42400, Loss: 0.0809, Accuracy: 96.09%\n",
      "Step:42500, Loss: 0.1086, Accuracy: 96.09%\n",
      "Step:42600, Loss: 0.1230, Accuracy: 95.31%\n",
      "Step:42700, Loss: 0.0524, Accuracy:100.00%\n",
      "Step:42800, Loss: 0.2196, Accuracy: 92.97%\n",
      "Step:42900, Loss: 0.1047, Accuracy: 96.09%\n",
      "Step:43000, Loss: 0.0848, Accuracy: 96.88%\n",
      "Step:43100, Loss: 0.1291, Accuracy: 98.44%\n",
      "Step:43200, Loss: 0.1856, Accuracy: 95.31%\n",
      "Step:43300, Loss: 0.2126, Accuracy: 96.09%\n",
      "Step:43400, Loss: 0.1927, Accuracy: 94.53%\n",
      "Step:43500, Loss: 0.1111, Accuracy: 97.66%\n",
      "Step:43600, Loss: 0.1442, Accuracy: 97.66%\n",
      "Step:43700, Loss: 0.1879, Accuracy: 95.31%\n",
      "Step:43800, Loss: 0.3408, Accuracy: 91.41%\n",
      "Step:43900, Loss: 0.1557, Accuracy: 97.66%\n",
      "Step:44000, Loss: 0.2201, Accuracy: 95.31%\n",
      "Step:44100, Loss: 0.1546, Accuracy: 96.09%\n",
      "Step:44200, Loss: 0.2277, Accuracy: 94.53%\n",
      "Step:44300, Loss: 0.0743, Accuracy: 98.44%\n",
      "Step:44400, Loss: 0.2078, Accuracy: 94.53%\n",
      "Step:44500, Loss: 0.2274, Accuracy: 92.97%\n",
      "Step:44600, Loss: 0.2305, Accuracy: 92.97%\n",
      "Step:44700, Loss: 0.0821, Accuracy: 97.66%\n",
      "Step:44800, Loss: 0.2350, Accuracy: 96.88%\n",
      "Step:44900, Loss: 0.1815, Accuracy: 96.88%\n",
      "Step:45000, Loss: 0.0956, Accuracy: 96.88%\n",
      "Step:45100, Loss: 0.1824, Accuracy: 95.31%\n",
      "Step:45200, Loss: 0.1119, Accuracy: 96.09%\n",
      "Step:45300, Loss: 0.1299, Accuracy: 96.88%\n",
      "Step:45400, Loss: 0.1759, Accuracy: 95.31%\n",
      "Step:45500, Loss: 0.1932, Accuracy: 96.88%\n",
      "Step:45600, Loss: 0.1174, Accuracy: 96.88%\n",
      "Step:45700, Loss: 0.1887, Accuracy: 94.53%\n",
      "Step:45800, Loss: 0.1370, Accuracy: 94.53%\n",
      "Step:45900, Loss: 0.1546, Accuracy: 96.88%\n",
      "Step:46000, Loss: 0.0982, Accuracy: 97.66%\n",
      "Step:46100, Loss: 0.1657, Accuracy: 95.31%\n",
      "Step:46200, Loss: 0.2508, Accuracy: 94.53%\n",
      "Step:46300, Loss: 0.1329, Accuracy: 98.44%\n",
      "Step:46400, Loss: 0.1190, Accuracy: 96.88%\n",
      "Step:46500, Loss: 0.1558, Accuracy: 96.88%\n",
      "Step:46600, Loss: 0.1402, Accuracy: 96.88%\n",
      "Step:46700, Loss: 0.1932, Accuracy: 96.09%\n",
      "Step:46800, Loss: 0.1232, Accuracy: 96.09%\n",
      "Step:46900, Loss: 0.1436, Accuracy: 96.09%\n",
      "Step:47000, Loss: 0.0675, Accuracy: 98.44%\n",
      "Step:47100, Loss: 0.1210, Accuracy: 96.09%\n",
      "Step:47200, Loss: 0.1528, Accuracy: 95.31%\n",
      "Step:47300, Loss: 0.1522, Accuracy: 96.88%\n",
      "Step:47400, Loss: 0.1269, Accuracy: 96.09%\n",
      "Step:47500, Loss: 0.1178, Accuracy: 97.66%\n",
      "Step:47600, Loss: 0.1388, Accuracy: 96.09%\n",
      "Step:47700, Loss: 0.1873, Accuracy: 93.75%\n",
      "Step:47800, Loss: 0.1272, Accuracy: 97.66%\n",
      "Step:47900, Loss: 0.1978, Accuracy: 96.88%\n",
      "Step:48000, Loss: 0.0645, Accuracy: 99.22%\n",
      "Step:48100, Loss: 0.1533, Accuracy: 93.75%\n",
      "Step:48200, Loss: 0.1760, Accuracy: 94.53%\n",
      "Step:48300, Loss: 0.1492, Accuracy: 96.88%\n",
      "Step:48400, Loss: 0.3450, Accuracy: 92.97%\n",
      "Step:48500, Loss: 0.1162, Accuracy: 96.88%\n",
      "Step:48600, Loss: 0.1335, Accuracy: 95.31%\n",
      "Step:48700, Loss: 0.1062, Accuracy: 96.88%\n",
      "Step:48800, Loss: 0.1613, Accuracy: 96.09%\n",
      "Step:48900, Loss: 0.2044, Accuracy: 96.88%\n",
      "Step:49000, Loss: 0.1995, Accuracy: 94.53%\n",
      "Step:49100, Loss: 0.1245, Accuracy: 96.09%\n",
      "Step:49200, Loss: 0.0705, Accuracy: 97.66%\n",
      "Step:49300, Loss: 0.0716, Accuracy: 98.44%\n",
      "Step:49400, Loss: 0.1790, Accuracy: 95.31%\n",
      "Step:49500, Loss: 0.1319, Accuracy: 96.09%\n",
      "Step:49600, Loss: 0.0813, Accuracy: 97.66%\n",
      "Step:49700, Loss: 0.1335, Accuracy: 96.88%\n",
      "Step:49800, Loss: 0.1410, Accuracy: 96.09%\n",
      "Step:49900, Loss: 0.0521, Accuracy: 99.22%\n",
      "Training Finished, Loss: 0.2341, Accuracy: 94.26%\n"
     ]
    }
   ],
   "source": [
    "for i in range(50000):\n",
    "    batch = mnist.train.next_batch(128)\n",
    "    _, loss_, acu = sess.run([train_step, loss, accuracy], {x: batch[0], y_: batch[1]})\n",
    "    if i % 100 == 0:\n",
    "        print(\"Step:{:>5}, Loss:{:>7.4f}, Accuracy:{:>7.2%}\".format(i, loss_, acu))\n",
    "loss_, acu = sess.run([loss, accuracy], {x: mnist.test.images, \n",
    "                                        y_: mnist.test.labels})\n",
    "print(\"Training Finished, Loss:{:>7.4f}, Accuracy:{:>7.2%}\".format(loss_, acu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
