{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 防止过拟合方法---dropout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义keep_prob参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#第一层\n",
    "W_h1 = tf.Variable(tf.truncated_normal([784, 512], mean=0., stddev=0.1))\n",
    "b_h1 = tf.Variable(tf.zeros([512]))\n",
    "h_linear_output1 = tf.matmul(x, W_h1) + b_h1\n",
    "h_output1 = tf.nn.tanh(h_linear_output1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#第二层\n",
    "W_h = tf.Variable(tf.truncated_normal([512, 256], mean=0., stddev=0.1))\n",
    "b_h = tf.Variable(tf.zeros([256]))\n",
    "h_linear_output2 = tf.matmul(h_output1, W_h) + b_h\n",
    "h_output2 = tf.nn.tanh(h_linear_output2)\n",
    "#dropout层\n",
    "h_fc_drop1 = tf.nn.dropout(h_output2, keep_prob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#第三层\n",
    "W_h = tf.Variable(tf.truncated_normal([256, 128], mean=0., stddev=0.1))\n",
    "b_h = tf.Variable(tf.zeros([128]))\n",
    "h_linear_output3 = tf.matmul(h_fc_drop1, W_h) + b_h\n",
    "h_output3 = tf.nn.tanh(h_linear_output3)\n",
    "#dropout层\n",
    "h_fc_drop2 = tf.nn.dropout(h_output3, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.truncated_normal([128, 10], mean=0., stddev=0.1))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "y = tf.matmul(h_fc_drop2, W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "softmax_result = tf.nn.softmax(y)\n",
    "pred = tf.argmax(softmax_result, axis=1)\n",
    "true = tf.argmax(y_, axis=1)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(pred, true), tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### keep_prob 设为1时的训练效果（即训练时不添加dropout）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:    0, Loss: 2.3768, Accuracy: 10.94%\n",
      "Step:  100, Loss: 0.2586, Accuracy: 89.06%\n",
      "Step:  200, Loss: 0.2087, Accuracy: 92.97%\n",
      "Step:  300, Loss: 0.2284, Accuracy: 93.75%\n",
      "Step:  400, Loss: 0.1337, Accuracy: 94.53%\n",
      "Step:  500, Loss: 0.1063, Accuracy: 95.31%\n",
      "Step:  600, Loss: 0.0785, Accuracy: 98.44%\n",
      "Step:  700, Loss: 0.1048, Accuracy: 96.88%\n",
      "Step:  800, Loss: 0.1048, Accuracy: 98.44%\n",
      "Step:  900, Loss: 0.0493, Accuracy: 96.88%\n",
      "Step: 1000, Loss: 0.0659, Accuracy: 97.66%\n",
      "Step: 1100, Loss: 0.0483, Accuracy: 99.22%\n",
      "Step: 1200, Loss: 0.1438, Accuracy: 96.09%\n",
      "Step: 1300, Loss: 0.0704, Accuracy: 97.66%\n",
      "Step: 1400, Loss: 0.0436, Accuracy: 98.44%\n",
      "Step: 1500, Loss: 0.0270, Accuracy: 99.22%\n",
      "Step: 1600, Loss: 0.0236, Accuracy: 99.22%\n",
      "Step: 1700, Loss: 0.0355, Accuracy: 99.22%\n",
      "Step: 1800, Loss: 0.1021, Accuracy: 98.44%\n",
      "Step: 1900, Loss: 0.0637, Accuracy: 97.66%\n",
      "Step: 2000, Loss: 0.0421, Accuracy: 99.22%\n",
      "Step: 2100, Loss: 0.0311, Accuracy: 99.22%\n",
      "Step: 2200, Loss: 0.0188, Accuracy: 99.22%\n",
      "Step: 2300, Loss: 0.0211, Accuracy: 99.22%\n",
      "Step: 2400, Loss: 0.0376, Accuracy: 98.44%\n",
      "Step: 2500, Loss: 0.0158, Accuracy: 99.22%\n",
      "Step: 2600, Loss: 0.0136, Accuracy: 99.22%\n",
      "Step: 2700, Loss: 0.0036, Accuracy:100.00%\n",
      "Step: 2800, Loss: 0.0049, Accuracy:100.00%\n",
      "Step: 2900, Loss: 0.0019, Accuracy:100.00%\n",
      "Step: 3000, Loss: 0.0124, Accuracy:100.00%\n",
      "Step: 3100, Loss: 0.0069, Accuracy:100.00%\n",
      "Step: 3200, Loss: 0.0154, Accuracy: 99.22%\n",
      "Step: 3300, Loss: 0.0027, Accuracy:100.00%\n",
      "Step: 3400, Loss: 0.0023, Accuracy:100.00%\n",
      "Step: 3500, Loss: 0.0012, Accuracy:100.00%\n",
      "Step: 3600, Loss: 0.0016, Accuracy:100.00%\n",
      "Step: 3700, Loss: 0.0010, Accuracy:100.00%\n",
      "Step: 3800, Loss: 0.0041, Accuracy:100.00%\n",
      "Step: 3900, Loss: 0.0017, Accuracy:100.00%\n",
      "Step: 4000, Loss: 0.0014, Accuracy:100.00%\n",
      "Step: 4100, Loss: 0.0024, Accuracy:100.00%\n",
      "Step: 4200, Loss: 0.0013, Accuracy:100.00%\n",
      "Step: 4300, Loss: 0.0025, Accuracy:100.00%\n",
      "Step: 4400, Loss: 0.0025, Accuracy:100.00%\n",
      "Step: 4500, Loss: 0.0015, Accuracy:100.00%\n",
      "Step: 4600, Loss: 0.0013, Accuracy:100.00%\n",
      "Step: 4700, Loss: 0.0019, Accuracy:100.00%\n",
      "Step: 4800, Loss: 0.0006, Accuracy:100.00%\n",
      "Step: 4900, Loss: 0.0009, Accuracy:100.00%\n",
      "Training Finished, Loss: 0.0691, Accuracy: 98.03%\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "for i in range(5000):\n",
    "    batch = mnist.train.next_batch(128)\n",
    "    _, loss_, acu = sess.run([train_step, loss, accuracy], {x: batch[0], y_: batch[1],keep_prob:1})\n",
    "    if i % 100 == 0:\n",
    "        print(\"Step:{:>5}, Loss:{:>7.4f}, Accuracy:{:>7.2%}\".format(i, loss_, acu))\n",
    "loss_, acu = sess.run([loss, accuracy], {x: mnist.test.images, \n",
    "                                                        y_: mnist.test.labels,keep_prob:1})\n",
    "print(\"Training Finished, Loss:{:>7.4f}, Accuracy:{:>7.2%}\".format(loss_, acu))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 添加dropout 的训练："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:    0, Loss: 2.4576, Accuracy:  8.59%\n",
      "Step:  100, Loss: 0.1826, Accuracy: 94.53%\n",
      "Step:  200, Loss: 0.2070, Accuracy: 92.19%\n",
      "Step:  300, Loss: 0.2159, Accuracy: 92.19%\n",
      "Step:  400, Loss: 0.2363, Accuracy: 94.53%\n",
      "Step:  500, Loss: 0.1746, Accuracy: 93.75%\n",
      "Step:  600, Loss: 0.1212, Accuracy: 96.09%\n",
      "Step:  700, Loss: 0.2347, Accuracy: 91.41%\n",
      "Step:  800, Loss: 0.2745, Accuracy: 92.97%\n",
      "Step:  900, Loss: 0.2629, Accuracy: 93.75%\n",
      "Step: 1000, Loss: 0.1604, Accuracy: 95.31%\n",
      "Step: 1100, Loss: 0.1082, Accuracy: 96.09%\n",
      "Step: 1200, Loss: 0.1129, Accuracy: 96.09%\n",
      "Step: 1300, Loss: 0.0900, Accuracy: 96.09%\n",
      "Step: 1400, Loss: 0.1682, Accuracy: 95.31%\n",
      "Step: 1500, Loss: 0.2857, Accuracy: 92.97%\n",
      "Step: 1600, Loss: 0.1641, Accuracy: 95.31%\n",
      "Step: 1700, Loss: 0.0474, Accuracy: 98.44%\n",
      "Step: 1800, Loss: 0.0967, Accuracy: 98.44%\n",
      "Step: 1900, Loss: 0.0449, Accuracy: 99.22%\n",
      "Step: 2000, Loss: 0.0597, Accuracy: 99.22%\n",
      "Step: 2100, Loss: 0.0960, Accuracy: 95.31%\n",
      "Step: 2200, Loss: 0.1097, Accuracy: 95.31%\n",
      "Step: 2300, Loss: 0.1102, Accuracy: 98.44%\n",
      "Step: 2400, Loss: 0.1225, Accuracy: 96.09%\n",
      "Step: 2500, Loss: 0.0645, Accuracy: 96.88%\n",
      "Step: 2600, Loss: 0.0464, Accuracy: 96.88%\n",
      "Step: 2700, Loss: 0.0031, Accuracy:100.00%\n",
      "Step: 2800, Loss: 0.0125, Accuracy:100.00%\n",
      "Step: 2900, Loss: 0.0810, Accuracy: 96.88%\n",
      "Step: 3000, Loss: 0.0229, Accuracy: 99.22%\n",
      "Step: 3100, Loss: 0.0583, Accuracy: 99.22%\n",
      "Step: 3200, Loss: 0.0132, Accuracy:100.00%\n",
      "Step: 3300, Loss: 0.0367, Accuracy: 98.44%\n",
      "Step: 3400, Loss: 0.0327, Accuracy: 99.22%\n",
      "Step: 3500, Loss: 0.0444, Accuracy: 98.44%\n",
      "Step: 3600, Loss: 0.0215, Accuracy: 99.22%\n",
      "Step: 3700, Loss: 0.0246, Accuracy: 99.22%\n",
      "Step: 3800, Loss: 0.0116, Accuracy:100.00%\n",
      "Step: 3900, Loss: 0.0565, Accuracy: 98.44%\n",
      "Step: 4000, Loss: 0.0366, Accuracy: 98.44%\n",
      "Step: 4100, Loss: 0.0137, Accuracy:100.00%\n",
      "Step: 4200, Loss: 0.0287, Accuracy: 98.44%\n",
      "Step: 4300, Loss: 0.0589, Accuracy: 99.22%\n",
      "Step: 4400, Loss: 0.0187, Accuracy: 98.44%\n",
      "Step: 4500, Loss: 0.0453, Accuracy: 97.66%\n",
      "Step: 4600, Loss: 0.0397, Accuracy: 97.66%\n",
      "Step: 4700, Loss: 0.0191, Accuracy: 99.22%\n",
      "Step: 4800, Loss: 0.0225, Accuracy: 99.22%\n",
      "Step: 4900, Loss: 0.0318, Accuracy: 98.44%\n",
      "Training Finished, Loss: 0.0723, Accuracy: 98.14%\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "for i in range(5000):\n",
    "    batch = mnist.train.next_batch(128)\n",
    "    _, loss_, acu = sess.run([train_step, loss, accuracy], {x: batch[0], y_: batch[1],keep_prob:0.8})\n",
    "    if i % 100 == 0:\n",
    "        print(\"Step:{:>5}, Loss:{:>7.4f}, Accuracy:{:>7.2%}\".format(i, loss_, acu))\n",
    "loss_, acu = sess.run([loss, accuracy], {x: mnist.test.images, \n",
    "                                                        y_: mnist.test.labels,keep_prob:1})\n",
    "print(\"Training Finished, Loss:{:>7.4f}, Accuracy:{:>7.2%}\".format(loss_, acu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
