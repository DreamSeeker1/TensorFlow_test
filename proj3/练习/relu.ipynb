{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting ../MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting ../MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ../MNIST_data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('../MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer1 = tf.layers.dense(inputs=x, \n",
    "                         units=20, \n",
    "                         activation=tf.nn.relu,                        \n",
    "                         bias_initializer=tf.constant_initializer(0),\n",
    "                         kernel_initializer=tf.truncated_normal_initializer(stddev=0.1)\n",
    "                        )\n",
    "layer2 = tf.layers.dense(inputs=layer1, \n",
    "                         units=20, \n",
    "                         activation=tf.nn.relu,                        \n",
    "                         bias_initializer=tf.constant_initializer(0),\n",
    "                         kernel_initializer=tf.truncated_normal_initializer(stddev=0.1)\n",
    "                        )\n",
    "layer3 = tf.layers.dense(inputs=layer2, \n",
    "                         units=20, \n",
    "                         activation=tf.nn.relu,                        \n",
    "                         bias_initializer=tf.constant_initializer(0),\n",
    "                         kernel_initializer=tf.truncated_normal_initializer(stddev=0.1)\n",
    "                        )\n",
    "layer4 = tf.layers.dense(inputs=layer3, \n",
    "                         units=20, \n",
    "                         activation=tf.nn.relu,                        \n",
    "                         bias_initializer=tf.constant_initializer(0),\n",
    "                         kernel_initializer=tf.truncated_normal_initializer(stddev=0.1)\n",
    "                        )\n",
    "layer5 = tf.layers.dense(inputs=layer4, \n",
    "                         units=20, \n",
    "                         activation=tf.nn.relu,                        \n",
    "                         bias_initializer=tf.constant_initializer(0),\n",
    "                         kernel_initializer=tf.truncated_normal_initializer(stddev=0.1)\n",
    "                        )\n",
    "layer6 = tf.layers.dense(inputs=layer5, \n",
    "                         units=20, \n",
    "                         activation=tf.nn.relu,                        \n",
    "                         bias_initializer=tf.constant_initializer(0),\n",
    "                         kernel_initializer=tf.truncated_normal_initializer(stddev=0.1)\n",
    "                        )\n",
    "y = tf.layers.dense(inputs=layer6, \n",
    "                    units=10, \n",
    "                    activation=None, \n",
    "                    bias_initializer=tf.constant_initializer(0), \n",
    "                    kernel_initializer=tf.truncated_normal_initializer(stddev=0.1)\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_step = tf.train.GradientDescentOptimizer(0.01).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "softmax_result = tf.nn.softmax(y)\n",
    "pred = tf.argmax(softmax_result, axis=1)\n",
    "true = tf.argmax(y_, axis=1)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(pred, true), tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:    0, Loss: 2.3025, Accuracy: 12.50%\n",
      "Step:  100, Loss: 2.3018, Accuracy: 14.06%\n",
      "Step:  200, Loss: 2.3026, Accuracy: 10.16%\n",
      "Step:  300, Loss: 2.3045, Accuracy:  9.38%\n",
      "Step:  400, Loss: 2.3040, Accuracy: 10.16%\n",
      "Step:  500, Loss: 2.3007, Accuracy: 11.72%\n",
      "Step:  600, Loss: 2.3003, Accuracy: 12.50%\n",
      "Step:  700, Loss: 2.3028, Accuracy:  7.81%\n",
      "Step:  800, Loss: 2.3032, Accuracy:  9.38%\n",
      "Step:  900, Loss: 2.3055, Accuracy: 10.16%\n",
      "Step: 1000, Loss: 2.2987, Accuracy: 14.06%\n",
      "Step: 1100, Loss: 2.2996, Accuracy: 14.06%\n",
      "Step: 1200, Loss: 2.2991, Accuracy: 10.94%\n",
      "Step: 1300, Loss: 2.3020, Accuracy: 11.72%\n",
      "Step: 1400, Loss: 2.3047, Accuracy:  9.38%\n",
      "Step: 1500, Loss: 2.3049, Accuracy:  8.59%\n",
      "Step: 1600, Loss: 2.3019, Accuracy: 11.72%\n",
      "Step: 1700, Loss: 2.3016, Accuracy: 13.28%\n",
      "Step: 1800, Loss: 2.2944, Accuracy: 16.41%\n",
      "Step: 1900, Loss: 2.2972, Accuracy: 12.50%\n",
      "Step: 2000, Loss: 2.3007, Accuracy: 14.06%\n",
      "Step: 2100, Loss: 2.3053, Accuracy:  7.03%\n",
      "Step: 2200, Loss: 2.3041, Accuracy:  7.81%\n",
      "Step: 2300, Loss: 2.3120, Accuracy:  7.81%\n",
      "Step: 2400, Loss: 2.3010, Accuracy: 12.50%\n",
      "Step: 2500, Loss: 2.3004, Accuracy: 12.50%\n",
      "Step: 2600, Loss: 2.2952, Accuracy: 16.41%\n",
      "Step: 2700, Loss: 2.2976, Accuracy: 13.28%\n",
      "Step: 2800, Loss: 2.2990, Accuracy:  8.59%\n",
      "Step: 2900, Loss: 2.2998, Accuracy: 10.16%\n",
      "Step: 3000, Loss: 2.3039, Accuracy: 10.16%\n",
      "Step: 3100, Loss: 2.2954, Accuracy: 17.19%\n",
      "Step: 3200, Loss: 2.2938, Accuracy: 12.50%\n",
      "Step: 3300, Loss: 2.3021, Accuracy:  9.38%\n",
      "Step: 3400, Loss: 2.3044, Accuracy: 12.50%\n",
      "Step: 3500, Loss: 2.3091, Accuracy:  8.59%\n",
      "Step: 3600, Loss: 2.2994, Accuracy: 14.06%\n",
      "Step: 3700, Loss: 2.2946, Accuracy: 15.62%\n",
      "Step: 3800, Loss: 2.3088, Accuracy:  8.59%\n",
      "Step: 3900, Loss: 2.3053, Accuracy:  9.38%\n",
      "Step: 4000, Loss: 2.3038, Accuracy:  9.38%\n",
      "Step: 4100, Loss: 2.2939, Accuracy: 17.19%\n",
      "Step: 4200, Loss: 2.2916, Accuracy: 14.84%\n",
      "Step: 4300, Loss: 2.3024, Accuracy: 10.94%\n",
      "Step: 4400, Loss: 2.2945, Accuracy: 14.84%\n",
      "Step: 4500, Loss: 2.3056, Accuracy:  6.25%\n",
      "Step: 4600, Loss: 2.3022, Accuracy: 11.72%\n",
      "Step: 4700, Loss: 2.3050, Accuracy:  8.59%\n",
      "Step: 4800, Loss: 2.3015, Accuracy:  7.81%\n",
      "Step: 4900, Loss: 2.3053, Accuracy: 10.16%\n",
      "Step: 5000, Loss: 2.2951, Accuracy: 13.28%\n",
      "Step: 5100, Loss: 2.3039, Accuracy: 10.94%\n",
      "Step: 5200, Loss: 2.2938, Accuracy: 15.62%\n",
      "Step: 5300, Loss: 2.3080, Accuracy:  7.03%\n",
      "Step: 5400, Loss: 2.3009, Accuracy: 12.50%\n",
      "Step: 5500, Loss: 2.3084, Accuracy:  7.03%\n",
      "Step: 5600, Loss: 2.2971, Accuracy: 11.72%\n",
      "Step: 5700, Loss: 2.3043, Accuracy: 10.94%\n",
      "Step: 5800, Loss: 2.3015, Accuracy:  9.38%\n",
      "Step: 5900, Loss: 2.2939, Accuracy: 11.72%\n",
      "Step: 6000, Loss: 2.3008, Accuracy:  8.59%\n",
      "Step: 6100, Loss: 2.3032, Accuracy: 10.16%\n",
      "Step: 6200, Loss: 2.3028, Accuracy:  6.25%\n",
      "Step: 6300, Loss: 2.3006, Accuracy: 12.50%\n",
      "Step: 6400, Loss: 2.3056, Accuracy:  6.25%\n",
      "Step: 6500, Loss: 2.3096, Accuracy:  5.47%\n",
      "Step: 6600, Loss: 2.3162, Accuracy:  6.25%\n",
      "Step: 6700, Loss: 2.3049, Accuracy: 14.06%\n",
      "Step: 6800, Loss: 2.3035, Accuracy: 10.16%\n",
      "Step: 6900, Loss: 2.2959, Accuracy: 12.50%\n",
      "Step: 7000, Loss: 2.3029, Accuracy: 10.94%\n",
      "Step: 7100, Loss: 2.2955, Accuracy: 14.06%\n",
      "Step: 7200, Loss: 2.2984, Accuracy: 10.94%\n",
      "Step: 7300, Loss: 2.3048, Accuracy: 11.72%\n",
      "Step: 7400, Loss: 2.2955, Accuracy: 12.50%\n",
      "Step: 7500, Loss: 2.2995, Accuracy: 14.84%\n",
      "Step: 7600, Loss: 2.2994, Accuracy:  9.38%\n",
      "Step: 7700, Loss: 2.3017, Accuracy: 12.50%\n",
      "Step: 7800, Loss: 2.2960, Accuracy: 10.16%\n",
      "Step: 7900, Loss: 2.3032, Accuracy:  8.59%\n",
      "Step: 8000, Loss: 2.3003, Accuracy: 10.16%\n",
      "Step: 8100, Loss: 2.2979, Accuracy: 11.72%\n",
      "Step: 8200, Loss: 2.3027, Accuracy:  7.81%\n",
      "Step: 8300, Loss: 2.2977, Accuracy: 10.16%\n",
      "Step: 8400, Loss: 2.3067, Accuracy:  9.38%\n",
      "Step: 8500, Loss: 2.2947, Accuracy: 15.62%\n",
      "Step: 8600, Loss: 2.3004, Accuracy:  8.59%\n",
      "Step: 8700, Loss: 2.2977, Accuracy: 10.94%\n",
      "Step: 8800, Loss: 2.2977, Accuracy: 10.16%\n",
      "Step: 8900, Loss: 2.3074, Accuracy:  7.03%\n",
      "Step: 9000, Loss: 2.3024, Accuracy: 10.94%\n",
      "Step: 9100, Loss: 2.2998, Accuracy: 13.28%\n",
      "Step: 9200, Loss: 2.3023, Accuracy:  7.81%\n",
      "Step: 9300, Loss: 2.2923, Accuracy: 16.41%\n",
      "Step: 9400, Loss: 2.3047, Accuracy:  6.25%\n",
      "Step: 9500, Loss: 2.2987, Accuracy: 13.28%\n",
      "Step: 9600, Loss: 2.2968, Accuracy: 13.28%\n",
      "Step: 9700, Loss: 2.3062, Accuracy:  8.59%\n",
      "Step: 9800, Loss: 2.2971, Accuracy: 13.28%\n",
      "Step: 9900, Loss: 2.3053, Accuracy:  6.25%\n",
      "Step:10000, Loss: 2.2992, Accuracy: 11.72%\n",
      "Step:10100, Loss: 2.3104, Accuracy:  7.03%\n",
      "Step:10200, Loss: 2.2954, Accuracy: 14.84%\n",
      "Step:10300, Loss: 2.3057, Accuracy:  8.59%\n",
      "Step:10400, Loss: 2.3020, Accuracy:  8.59%\n",
      "Step:10500, Loss: 2.2995, Accuracy: 10.16%\n",
      "Step:10600, Loss: 2.3011, Accuracy: 10.16%\n",
      "Step:10700, Loss: 2.2965, Accuracy: 11.72%\n",
      "Step:10800, Loss: 2.3009, Accuracy: 10.16%\n",
      "Step:10900, Loss: 2.2967, Accuracy: 11.72%\n",
      "Step:11000, Loss: 2.2988, Accuracy: 10.16%\n",
      "Step:11100, Loss: 2.3088, Accuracy:  6.25%\n",
      "Step:11200, Loss: 2.2900, Accuracy: 14.06%\n",
      "Step:11300, Loss: 2.2946, Accuracy: 11.72%\n",
      "Step:11400, Loss: 2.2891, Accuracy: 14.84%\n",
      "Step:11500, Loss: 2.2899, Accuracy: 11.72%\n",
      "Step:11600, Loss: 2.2909, Accuracy: 14.06%\n",
      "Step:11700, Loss: 2.3147, Accuracy:  5.47%\n",
      "Step:11800, Loss: 2.3012, Accuracy:  9.38%\n",
      "Step:11900, Loss: 2.3016, Accuracy:  8.59%\n",
      "Step:12000, Loss: 2.2938, Accuracy: 13.28%\n",
      "Step:12100, Loss: 2.2923, Accuracy: 12.50%\n",
      "Step:12200, Loss: 2.2944, Accuracy:  7.81%\n",
      "Step:12300, Loss: 2.2867, Accuracy: 13.28%\n",
      "Step:12400, Loss: 2.2834, Accuracy: 14.84%\n",
      "Step:12500, Loss: 2.2819, Accuracy: 14.06%\n",
      "Step:12600, Loss: 2.2786, Accuracy: 14.06%\n",
      "Step:12700, Loss: 2.2795, Accuracy: 13.28%\n",
      "Step:12800, Loss: 2.2835, Accuracy: 15.62%\n",
      "Step:12900, Loss: 2.2831, Accuracy: 14.06%\n",
      "Step:13000, Loss: 2.2578, Accuracy: 20.31%\n",
      "Step:13100, Loss: 2.2476, Accuracy: 22.66%\n",
      "Step:13200, Loss: 2.2350, Accuracy: 22.66%\n",
      "Step:13300, Loss: 2.2105, Accuracy: 21.09%\n",
      "Step:13400, Loss: 2.1600, Accuracy: 26.56%\n",
      "Step:13500, Loss: 2.1668, Accuracy: 21.09%\n",
      "Step:13600, Loss: 2.0843, Accuracy: 21.88%\n",
      "Step:13700, Loss: 2.0415, Accuracy: 23.44%\n",
      "Step:13800, Loss: 1.9899, Accuracy: 21.09%\n",
      "Step:13900, Loss: 1.9530, Accuracy: 19.53%\n",
      "Step:14000, Loss: 1.9691, Accuracy: 17.97%\n",
      "Step:14100, Loss: 1.8938, Accuracy: 19.53%\n",
      "Step:14200, Loss: 1.8357, Accuracy: 23.44%\n",
      "Step:14300, Loss: 1.7466, Accuracy: 31.25%\n",
      "Step:14400, Loss: 1.7976, Accuracy: 31.25%\n",
      "Step:14500, Loss: 1.8696, Accuracy: 26.56%\n",
      "Step:14600, Loss: 1.7391, Accuracy: 32.03%\n",
      "Step:14700, Loss: 1.5451, Accuracy: 40.62%\n",
      "Step:14800, Loss: 1.5005, Accuracy: 39.06%\n",
      "Step:14900, Loss: 1.4966, Accuracy: 38.28%\n",
      "Step:15000, Loss: 1.5809, Accuracy: 34.38%\n",
      "Step:15100, Loss: 1.4907, Accuracy: 34.38%\n",
      "Step:15200, Loss: 1.4628, Accuracy: 40.62%\n",
      "Step:15300, Loss: 1.5693, Accuracy: 26.56%\n",
      "Step:15400, Loss: 1.3630, Accuracy: 41.41%\n",
      "Step:15500, Loss: 1.3418, Accuracy: 42.19%\n",
      "Step:15600, Loss: 1.3309, Accuracy: 38.28%\n",
      "Step:15700, Loss: 1.2806, Accuracy: 44.53%\n",
      "Step:15800, Loss: 1.2487, Accuracy: 48.44%\n",
      "Step:15900, Loss: 1.2694, Accuracy: 47.66%\n",
      "Step:16000, Loss: 1.2382, Accuracy: 40.62%\n",
      "Step:16100, Loss: 1.2185, Accuracy: 39.84%\n",
      "Step:16200, Loss: 1.4465, Accuracy: 46.88%\n",
      "Step:16300, Loss: 1.2588, Accuracy: 42.97%\n",
      "Step:16400, Loss: 1.2617, Accuracy: 49.22%\n",
      "Step:16500, Loss: 1.2310, Accuracy: 49.22%\n",
      "Step:16600, Loss: 1.1922, Accuracy: 57.81%\n",
      "Step:16700, Loss: 1.0417, Accuracy: 52.34%\n",
      "Step:16800, Loss: 1.3227, Accuracy: 55.47%\n",
      "Step:16900, Loss: 1.2128, Accuracy: 49.22%\n",
      "Step:17000, Loss: 1.3066, Accuracy: 43.75%\n",
      "Step:17100, Loss: 1.1741, Accuracy: 50.00%\n",
      "Step:17200, Loss: 1.1218, Accuracy: 61.72%\n",
      "Step:17300, Loss: 1.2781, Accuracy: 53.12%\n",
      "Step:17400, Loss: 0.9595, Accuracy: 64.84%\n",
      "Step:17500, Loss: 1.0487, Accuracy: 55.47%\n",
      "Step:17600, Loss: 1.1290, Accuracy: 56.25%\n",
      "Step:17700, Loss: 1.1014, Accuracy: 57.03%\n",
      "Step:17800, Loss: 1.1156, Accuracy: 60.16%\n",
      "Step:17900, Loss: 1.0522, Accuracy: 57.81%\n",
      "Step:18000, Loss: 1.0084, Accuracy: 62.50%\n",
      "Step:18100, Loss: 0.9267, Accuracy: 64.84%\n",
      "Step:18200, Loss: 1.0982, Accuracy: 55.47%\n",
      "Step:18300, Loss: 1.1673, Accuracy: 58.59%\n",
      "Step:18400, Loss: 1.1328, Accuracy: 60.94%\n",
      "Step:18500, Loss: 0.9040, Accuracy: 66.41%\n",
      "Step:18600, Loss: 0.8422, Accuracy: 64.84%\n",
      "Step:18700, Loss: 1.1479, Accuracy: 52.34%\n",
      "Step:18800, Loss: 0.8957, Accuracy: 66.41%\n",
      "Step:18900, Loss: 0.9739, Accuracy: 62.50%\n",
      "Step:19000, Loss: 1.1502, Accuracy: 59.38%\n",
      "Step:19100, Loss: 0.8604, Accuracy: 64.06%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:19200, Loss: 1.1131, Accuracy: 63.28%\n",
      "Step:19300, Loss: 0.8903, Accuracy: 69.53%\n",
      "Step:19400, Loss: 0.9359, Accuracy: 64.06%\n",
      "Step:19500, Loss: 0.9695, Accuracy: 63.28%\n",
      "Step:19600, Loss: 0.8799, Accuracy: 67.97%\n",
      "Step:19700, Loss: 0.9331, Accuracy: 64.84%\n",
      "Step:19800, Loss: 0.6366, Accuracy: 75.78%\n",
      "Step:19900, Loss: 0.8350, Accuracy: 69.53%\n",
      "Step:20000, Loss: 0.7193, Accuracy: 73.44%\n",
      "Step:20100, Loss: 1.1688, Accuracy: 65.62%\n",
      "Step:20200, Loss: 0.9490, Accuracy: 70.31%\n",
      "Step:20300, Loss: 0.8138, Accuracy: 71.09%\n",
      "Step:20400, Loss: 0.8269, Accuracy: 67.19%\n",
      "Step:20500, Loss: 0.8162, Accuracy: 77.34%\n",
      "Step:20600, Loss: 0.7258, Accuracy: 78.12%\n",
      "Step:20700, Loss: 0.7640, Accuracy: 72.66%\n",
      "Step:20800, Loss: 0.7784, Accuracy: 74.22%\n",
      "Step:20900, Loss: 0.6676, Accuracy: 80.47%\n",
      "Step:21000, Loss: 0.6935, Accuracy: 79.69%\n",
      "Step:21100, Loss: 0.6906, Accuracy: 82.81%\n",
      "Step:21200, Loss: 0.7306, Accuracy: 75.78%\n",
      "Step:21300, Loss: 0.7218, Accuracy: 77.34%\n",
      "Step:21400, Loss: 0.6606, Accuracy: 77.34%\n",
      "Step:21500, Loss: 0.7395, Accuracy: 79.69%\n",
      "Step:21600, Loss: 0.6351, Accuracy: 76.56%\n",
      "Step:21700, Loss: 0.7266, Accuracy: 80.47%\n",
      "Step:21800, Loss: 0.7080, Accuracy: 78.12%\n",
      "Step:21900, Loss: 0.4517, Accuracy: 83.59%\n",
      "Step:22000, Loss: 0.5676, Accuracy: 78.12%\n",
      "Step:22100, Loss: 0.5206, Accuracy: 81.25%\n",
      "Step:22200, Loss: 0.4022, Accuracy: 86.72%\n",
      "Step:22300, Loss: 0.5646, Accuracy: 86.72%\n",
      "Step:22400, Loss: 0.4647, Accuracy: 84.38%\n",
      "Step:22500, Loss: 0.5574, Accuracy: 82.03%\n",
      "Step:22600, Loss: 0.4048, Accuracy: 89.06%\n",
      "Step:22700, Loss: 0.5052, Accuracy: 82.03%\n",
      "Step:22800, Loss: 0.3650, Accuracy: 86.72%\n",
      "Step:22900, Loss: 0.5153, Accuracy: 82.81%\n",
      "Step:23000, Loss: 0.5886, Accuracy: 82.03%\n",
      "Step:23100, Loss: 0.5982, Accuracy: 82.81%\n",
      "Step:23200, Loss: 0.4329, Accuracy: 88.28%\n",
      "Step:23300, Loss: 0.4547, Accuracy: 83.59%\n",
      "Step:23400, Loss: 0.5585, Accuracy: 81.25%\n",
      "Step:23500, Loss: 0.6177, Accuracy: 86.72%\n",
      "Step:23600, Loss: 0.8515, Accuracy: 79.69%\n",
      "Step:23700, Loss: 0.5970, Accuracy: 86.72%\n",
      "Step:23800, Loss: 0.4282, Accuracy: 86.72%\n",
      "Step:23900, Loss: 0.5335, Accuracy: 83.59%\n",
      "Step:24000, Loss: 0.4696, Accuracy: 85.94%\n",
      "Step:24100, Loss: 0.4273, Accuracy: 89.06%\n",
      "Step:24200, Loss: 0.4852, Accuracy: 82.03%\n",
      "Step:24300, Loss: 0.3990, Accuracy: 87.50%\n",
      "Step:24400, Loss: 0.5322, Accuracy: 89.06%\n",
      "Step:24500, Loss: 0.5627, Accuracy: 82.81%\n",
      "Step:24600, Loss: 0.5706, Accuracy: 82.81%\n",
      "Step:24700, Loss: 0.5604, Accuracy: 82.81%\n",
      "Step:24800, Loss: 0.2343, Accuracy: 94.53%\n",
      "Step:24900, Loss: 0.5115, Accuracy: 85.94%\n",
      "Step:25000, Loss: 0.4200, Accuracy: 91.41%\n",
      "Step:25100, Loss: 0.3735, Accuracy: 88.28%\n",
      "Step:25200, Loss: 0.3851, Accuracy: 88.28%\n",
      "Step:25300, Loss: 0.4661, Accuracy: 88.28%\n",
      "Step:25400, Loss: 0.4852, Accuracy: 87.50%\n",
      "Step:25500, Loss: 0.4020, Accuracy: 89.84%\n",
      "Step:25600, Loss: 0.3501, Accuracy: 85.94%\n",
      "Step:25700, Loss: 0.4614, Accuracy: 88.28%\n",
      "Step:25800, Loss: 0.2538, Accuracy: 89.84%\n",
      "Step:25900, Loss: 0.4007, Accuracy: 89.84%\n",
      "Step:26000, Loss: 0.3973, Accuracy: 89.06%\n",
      "Step:26100, Loss: 0.5034, Accuracy: 86.72%\n",
      "Step:26200, Loss: 0.4473, Accuracy: 85.16%\n",
      "Step:26300, Loss: 0.4601, Accuracy: 86.72%\n",
      "Step:26400, Loss: 0.2089, Accuracy: 93.75%\n",
      "Step:26500, Loss: 0.3841, Accuracy: 85.16%\n",
      "Step:26600, Loss: 0.2759, Accuracy: 88.28%\n",
      "Step:26700, Loss: 0.3009, Accuracy: 90.62%\n",
      "Step:26800, Loss: 0.2285, Accuracy: 92.19%\n",
      "Step:26900, Loss: 0.3780, Accuracy: 89.84%\n",
      "Step:27000, Loss: 0.4541, Accuracy: 88.28%\n",
      "Step:27100, Loss: 0.5494, Accuracy: 82.03%\n",
      "Step:27200, Loss: 0.3948, Accuracy: 89.84%\n",
      "Step:27300, Loss: 0.2862, Accuracy: 91.41%\n",
      "Step:27400, Loss: 0.2297, Accuracy: 93.75%\n",
      "Step:27500, Loss: 0.3627, Accuracy: 89.06%\n",
      "Step:27600, Loss: 0.3344, Accuracy: 91.41%\n",
      "Step:27700, Loss: 0.3376, Accuracy: 88.28%\n",
      "Step:27800, Loss: 0.7304, Accuracy: 82.81%\n",
      "Step:27900, Loss: 0.3202, Accuracy: 89.06%\n",
      "Step:28000, Loss: 0.4210, Accuracy: 86.72%\n",
      "Step:28100, Loss: 0.4201, Accuracy: 88.28%\n",
      "Step:28200, Loss: 0.2986, Accuracy: 92.19%\n",
      "Step:28300, Loss: 0.1588, Accuracy: 95.31%\n",
      "Step:28400, Loss: 0.3944, Accuracy: 86.72%\n",
      "Step:28500, Loss: 0.2755, Accuracy: 89.06%\n",
      "Step:28600, Loss: 0.3995, Accuracy: 84.38%\n",
      "Step:28700, Loss: 0.3006, Accuracy: 91.41%\n",
      "Step:28800, Loss: 0.2961, Accuracy: 92.97%\n",
      "Step:28900, Loss: 0.2167, Accuracy: 94.53%\n",
      "Step:29000, Loss: 0.4465, Accuracy: 86.72%\n",
      "Step:29100, Loss: 0.7566, Accuracy: 88.28%\n",
      "Step:29200, Loss: 0.2394, Accuracy: 93.75%\n",
      "Step:29300, Loss: 0.3897, Accuracy: 89.84%\n",
      "Step:29400, Loss: 0.3223, Accuracy: 91.41%\n",
      "Step:29500, Loss: 0.3968, Accuracy: 89.06%\n",
      "Step:29600, Loss: 0.3326, Accuracy: 92.19%\n",
      "Step:29700, Loss: 0.3556, Accuracy: 90.62%\n",
      "Step:29800, Loss: 0.2693, Accuracy: 90.62%\n",
      "Step:29900, Loss: 0.2263, Accuracy: 92.97%\n",
      "Step:30000, Loss: 0.3863, Accuracy: 87.50%\n",
      "Step:30100, Loss: 0.4195, Accuracy: 86.72%\n",
      "Step:30200, Loss: 0.3485, Accuracy: 88.28%\n",
      "Step:30300, Loss: 0.4233, Accuracy: 91.41%\n",
      "Step:30400, Loss: 0.2207, Accuracy: 92.19%\n",
      "Step:30500, Loss: 0.3314, Accuracy: 90.62%\n",
      "Step:30600, Loss: 0.3244, Accuracy: 92.19%\n",
      "Step:30700, Loss: 0.3644, Accuracy: 89.06%\n",
      "Step:30800, Loss: 0.4168, Accuracy: 90.62%\n",
      "Step:30900, Loss: 0.2821, Accuracy: 92.97%\n",
      "Step:31000, Loss: 0.3058, Accuracy: 91.41%\n",
      "Step:31100, Loss: 0.2491, Accuracy: 91.41%\n",
      "Step:31200, Loss: 0.3083, Accuracy: 92.19%\n",
      "Step:31300, Loss: 0.3288, Accuracy: 88.28%\n",
      "Step:31400, Loss: 0.2318, Accuracy: 94.53%\n",
      "Step:31500, Loss: 0.1887, Accuracy: 93.75%\n",
      "Step:31600, Loss: 0.3361, Accuracy: 90.62%\n",
      "Step:31700, Loss: 0.2229, Accuracy: 92.19%\n",
      "Step:31800, Loss: 0.3228, Accuracy: 91.41%\n",
      "Step:31900, Loss: 0.2524, Accuracy: 92.97%\n",
      "Step:32000, Loss: 0.3368, Accuracy: 90.62%\n",
      "Step:32100, Loss: 0.1669, Accuracy: 95.31%\n",
      "Step:32200, Loss: 0.1290, Accuracy: 96.09%\n",
      "Step:32300, Loss: 0.2794, Accuracy: 90.62%\n",
      "Step:32400, Loss: 0.1384, Accuracy: 96.09%\n",
      "Step:32500, Loss: 0.2901, Accuracy: 92.97%\n",
      "Step:32600, Loss: 0.2670, Accuracy: 90.62%\n",
      "Step:32700, Loss: 0.2556, Accuracy: 92.19%\n",
      "Step:32800, Loss: 0.1691, Accuracy: 95.31%\n",
      "Step:32900, Loss: 0.2393, Accuracy: 93.75%\n",
      "Step:33000, Loss: 0.2773, Accuracy: 92.97%\n",
      "Step:33100, Loss: 0.2399, Accuracy: 91.41%\n",
      "Step:33200, Loss: 0.2516, Accuracy: 93.75%\n",
      "Step:33300, Loss: 0.2611, Accuracy: 89.84%\n",
      "Step:33400, Loss: 0.3421, Accuracy: 84.38%\n",
      "Step:33500, Loss: 0.2823, Accuracy: 91.41%\n",
      "Step:33600, Loss: 0.3957, Accuracy: 89.84%\n",
      "Step:33700, Loss: 0.1624, Accuracy: 95.31%\n",
      "Step:33800, Loss: 0.2060, Accuracy: 93.75%\n",
      "Step:33900, Loss: 0.2769, Accuracy: 91.41%\n",
      "Step:34000, Loss: 0.3237, Accuracy: 90.62%\n",
      "Step:34100, Loss: 0.2737, Accuracy: 90.62%\n",
      "Step:34200, Loss: 0.2802, Accuracy: 93.75%\n",
      "Step:34300, Loss: 0.2247, Accuracy: 89.06%\n",
      "Step:34400, Loss: 0.2038, Accuracy: 93.75%\n",
      "Step:34500, Loss: 0.3471, Accuracy: 89.06%\n",
      "Step:34600, Loss: 0.1683, Accuracy: 93.75%\n",
      "Step:34700, Loss: 0.3104, Accuracy: 91.41%\n",
      "Step:34800, Loss: 0.3398, Accuracy: 92.19%\n",
      "Step:34900, Loss: 0.1785, Accuracy: 94.53%\n",
      "Step:35000, Loss: 0.3165, Accuracy: 92.19%\n",
      "Step:35100, Loss: 0.3235, Accuracy: 86.72%\n",
      "Step:35200, Loss: 0.4417, Accuracy: 83.59%\n",
      "Step:35300, Loss: 0.2316, Accuracy: 92.19%\n",
      "Step:35400, Loss: 0.1384, Accuracy: 96.09%\n",
      "Step:35500, Loss: 0.2507, Accuracy: 90.62%\n",
      "Step:35600, Loss: 0.3319, Accuracy: 89.84%\n",
      "Step:35700, Loss: 0.2178, Accuracy: 93.75%\n",
      "Step:35800, Loss: 0.2050, Accuracy: 91.41%\n",
      "Step:35900, Loss: 0.2554, Accuracy: 94.53%\n",
      "Step:36000, Loss: 0.1731, Accuracy: 94.53%\n",
      "Step:36100, Loss: 0.3966, Accuracy: 92.97%\n",
      "Step:36200, Loss: 0.2663, Accuracy: 92.19%\n",
      "Step:36300, Loss: 0.2550, Accuracy: 93.75%\n",
      "Step:36400, Loss: 0.5278, Accuracy: 92.97%\n",
      "Step:36500, Loss: 0.2391, Accuracy: 92.97%\n",
      "Step:36600, Loss: 0.2126, Accuracy: 92.19%\n",
      "Step:36700, Loss: 0.2638, Accuracy: 92.97%\n",
      "Step:36800, Loss: 0.4580, Accuracy: 88.28%\n",
      "Step:36900, Loss: 0.1616, Accuracy: 96.09%\n",
      "Step:37000, Loss: 0.2799, Accuracy: 90.62%\n",
      "Step:37100, Loss: 0.3030, Accuracy: 89.84%\n",
      "Step:37200, Loss: 0.1378, Accuracy: 95.31%\n",
      "Step:37300, Loss: 0.1996, Accuracy: 92.19%\n",
      "Step:37400, Loss: 0.1202, Accuracy: 94.53%\n",
      "Step:37500, Loss: 0.2064, Accuracy: 94.53%\n",
      "Step:37600, Loss: 0.2545, Accuracy: 93.75%\n",
      "Step:37700, Loss: 0.3202, Accuracy: 93.75%\n",
      "Step:37800, Loss: 0.1315, Accuracy: 96.88%\n",
      "Step:37900, Loss: 0.3607, Accuracy: 89.06%\n",
      "Step:38000, Loss: 0.2317, Accuracy: 92.97%\n",
      "Step:38100, Loss: 0.2640, Accuracy: 91.41%\n",
      "Step:38200, Loss: 0.2106, Accuracy: 92.97%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:38300, Loss: 0.2989, Accuracy: 89.84%\n",
      "Step:38400, Loss: 0.3117, Accuracy: 92.19%\n",
      "Step:38500, Loss: 0.1560, Accuracy: 93.75%\n",
      "Step:38600, Loss: 0.1655, Accuracy: 95.31%\n",
      "Step:38700, Loss: 0.2936, Accuracy: 92.97%\n",
      "Step:38800, Loss: 0.2392, Accuracy: 94.53%\n",
      "Step:38900, Loss: 0.2444, Accuracy: 93.75%\n",
      "Step:39000, Loss: 0.1974, Accuracy: 93.75%\n",
      "Step:39100, Loss: 0.2376, Accuracy: 94.53%\n",
      "Step:39200, Loss: 0.1260, Accuracy: 96.88%\n",
      "Step:39300, Loss: 0.3114, Accuracy: 92.19%\n",
      "Step:39400, Loss: 0.1383, Accuracy: 96.09%\n",
      "Step:39500, Loss: 0.3280, Accuracy: 89.06%\n",
      "Step:39600, Loss: 0.2375, Accuracy: 92.19%\n",
      "Step:39700, Loss: 0.1938, Accuracy: 94.53%\n",
      "Step:39800, Loss: 0.2484, Accuracy: 93.75%\n",
      "Step:39900, Loss: 0.2376, Accuracy: 92.97%\n",
      "Step:40000, Loss: 0.2323, Accuracy: 95.31%\n",
      "Step:40100, Loss: 0.3726, Accuracy: 89.84%\n",
      "Step:40200, Loss: 0.1016, Accuracy: 96.88%\n",
      "Step:40300, Loss: 0.3413, Accuracy: 91.41%\n",
      "Step:40400, Loss: 0.2466, Accuracy: 90.62%\n",
      "Step:40500, Loss: 0.2366, Accuracy: 91.41%\n",
      "Step:40600, Loss: 0.1539, Accuracy: 95.31%\n",
      "Step:40700, Loss: 0.3537, Accuracy: 92.97%\n",
      "Step:40800, Loss: 0.1376, Accuracy: 96.88%\n",
      "Step:40900, Loss: 0.2014, Accuracy: 92.97%\n",
      "Step:41000, Loss: 0.1614, Accuracy: 96.09%\n",
      "Step:41100, Loss: 0.2065, Accuracy: 92.97%\n",
      "Step:41200, Loss: 0.3741, Accuracy: 89.84%\n",
      "Step:41300, Loss: 0.1923, Accuracy: 98.44%\n",
      "Step:41400, Loss: 0.2549, Accuracy: 92.19%\n",
      "Step:41500, Loss: 0.4495, Accuracy: 91.41%\n",
      "Step:41600, Loss: 0.1587, Accuracy: 94.53%\n",
      "Step:41700, Loss: 0.1283, Accuracy: 96.09%\n",
      "Step:41800, Loss: 0.2823, Accuracy: 92.97%\n",
      "Step:41900, Loss: 0.4615, Accuracy: 89.06%\n",
      "Step:42000, Loss: 0.1606, Accuracy: 96.88%\n",
      "Step:42100, Loss: 0.2139, Accuracy: 93.75%\n",
      "Step:42200, Loss: 0.1598, Accuracy: 96.09%\n",
      "Step:42300, Loss: 0.1605, Accuracy: 95.31%\n",
      "Step:42400, Loss: 0.1836, Accuracy: 94.53%\n",
      "Step:42500, Loss: 0.2506, Accuracy: 96.09%\n",
      "Step:42600, Loss: 0.2301, Accuracy: 92.97%\n",
      "Step:42700, Loss: 0.1458, Accuracy: 94.53%\n",
      "Step:42800, Loss: 0.1923, Accuracy: 96.09%\n",
      "Step:42900, Loss: 0.2779, Accuracy: 94.53%\n",
      "Step:43000, Loss: 0.3624, Accuracy: 90.62%\n",
      "Step:43100, Loss: 0.1267, Accuracy: 96.88%\n",
      "Step:43200, Loss: 0.2228, Accuracy: 92.19%\n",
      "Step:43300, Loss: 0.2273, Accuracy: 92.19%\n",
      "Step:43400, Loss: 0.1810, Accuracy: 93.75%\n",
      "Step:43500, Loss: 0.2649, Accuracy: 90.62%\n",
      "Step:43600, Loss: 0.2635, Accuracy: 92.19%\n",
      "Step:43700, Loss: 0.1565, Accuracy: 93.75%\n",
      "Step:43800, Loss: 0.1444, Accuracy: 94.53%\n",
      "Step:43900, Loss: 0.2664, Accuracy: 91.41%\n",
      "Step:44000, Loss: 0.0721, Accuracy: 99.22%\n",
      "Step:44100, Loss: 0.2106, Accuracy: 95.31%\n",
      "Step:44200, Loss: 0.2372, Accuracy: 92.97%\n",
      "Step:44300, Loss: 0.1659, Accuracy: 94.53%\n",
      "Step:44400, Loss: 0.2548, Accuracy: 93.75%\n",
      "Step:44500, Loss: 0.1666, Accuracy: 95.31%\n",
      "Step:44600, Loss: 0.2495, Accuracy: 90.62%\n",
      "Step:44700, Loss: 0.2617, Accuracy: 90.62%\n",
      "Step:44800, Loss: 0.2966, Accuracy: 89.84%\n",
      "Step:44900, Loss: 0.1098, Accuracy: 96.88%\n",
      "Step:45000, Loss: 0.2171, Accuracy: 93.75%\n",
      "Step:45100, Loss: 0.1824, Accuracy: 93.75%\n",
      "Step:45200, Loss: 0.1729, Accuracy: 96.09%\n",
      "Step:45300, Loss: 0.1880, Accuracy: 91.41%\n",
      "Step:45400, Loss: 0.1525, Accuracy: 93.75%\n",
      "Step:45500, Loss: 0.1408, Accuracy: 96.88%\n",
      "Step:45600, Loss: 0.1972, Accuracy: 93.75%\n",
      "Step:45700, Loss: 0.1936, Accuracy: 94.53%\n",
      "Step:45800, Loss: 0.1203, Accuracy: 95.31%\n",
      "Step:45900, Loss: 0.3378, Accuracy: 92.19%\n",
      "Step:46000, Loss: 0.1452, Accuracy: 94.53%\n",
      "Step:46100, Loss: 0.1681, Accuracy: 93.75%\n",
      "Step:46200, Loss: 0.3252, Accuracy: 88.28%\n",
      "Step:46300, Loss: 0.1715, Accuracy: 93.75%\n",
      "Step:46400, Loss: 0.2111, Accuracy: 94.53%\n",
      "Step:46500, Loss: 0.1297, Accuracy: 96.09%\n",
      "Step:46600, Loss: 0.1895, Accuracy: 92.97%\n",
      "Step:46700, Loss: 0.1772, Accuracy: 92.97%\n",
      "Step:46800, Loss: 0.1898, Accuracy: 94.53%\n",
      "Step:46900, Loss: 0.2761, Accuracy: 92.19%\n",
      "Step:47000, Loss: 0.1683, Accuracy: 95.31%\n",
      "Step:47100, Loss: 0.1301, Accuracy: 96.09%\n",
      "Step:47200, Loss: 0.3990, Accuracy: 88.28%\n",
      "Step:47300, Loss: 0.1265, Accuracy: 95.31%\n",
      "Step:47400, Loss: 0.2465, Accuracy: 92.97%\n",
      "Step:47500, Loss: 0.2470, Accuracy: 91.41%\n",
      "Step:47600, Loss: 0.2877, Accuracy: 92.97%\n",
      "Step:47700, Loss: 0.0992, Accuracy: 97.66%\n",
      "Step:47800, Loss: 0.1322, Accuracy: 95.31%\n",
      "Step:47900, Loss: 0.2539, Accuracy: 90.62%\n",
      "Step:48000, Loss: 0.2711, Accuracy: 92.97%\n",
      "Step:48100, Loss: 0.1089, Accuracy: 96.09%\n",
      "Step:48200, Loss: 0.2790, Accuracy: 92.97%\n",
      "Step:48300, Loss: 0.1425, Accuracy: 95.31%\n",
      "Step:48400, Loss: 0.1581, Accuracy: 96.88%\n",
      "Step:48500, Loss: 0.2038, Accuracy: 94.53%\n",
      "Step:48600, Loss: 0.1203, Accuracy: 97.66%\n",
      "Step:48700, Loss: 0.3052, Accuracy: 92.97%\n",
      "Step:48800, Loss: 0.1591, Accuracy: 95.31%\n",
      "Step:48900, Loss: 0.1386, Accuracy: 95.31%\n",
      "Step:49000, Loss: 0.0938, Accuracy: 98.44%\n",
      "Step:49100, Loss: 0.1465, Accuracy: 95.31%\n",
      "Step:49200, Loss: 0.1767, Accuracy: 95.31%\n",
      "Step:49300, Loss: 0.2148, Accuracy: 93.75%\n",
      "Step:49400, Loss: 0.2729, Accuracy: 93.75%\n",
      "Step:49500, Loss: 0.1645, Accuracy: 96.88%\n",
      "Step:49600, Loss: 0.1188, Accuracy: 96.09%\n",
      "Step:49700, Loss: 0.1282, Accuracy: 97.66%\n",
      "Step:49800, Loss: 0.1332, Accuracy: 95.31%\n",
      "Step:49900, Loss: 0.3371, Accuracy: 92.97%\n",
      "Training Finished, Loss: 0.2551, Accuracy: 92.99%\n"
     ]
    }
   ],
   "source": [
    "for i in range(50000):\n",
    "    batch = mnist.train.next_batch(128)\n",
    "    _, loss_, acu = sess.run([train_step, loss, accuracy], {x: batch[0], y_: batch[1]})\n",
    "    if i % 100 == 0:\n",
    "        print(\"Step:{:>5}, Loss:{:>7.4f}, Accuracy:{:>7.2%}\".format(i, loss_, acu))\n",
    "loss_, acu = sess.run([loss, accuracy], {x: mnist.test.images, \n",
    "                                        y_: mnist.test.labels})\n",
    "print(\"Training Finished, Loss:{:>7.4f}, Accuracy:{:>7.2%}\".format(loss_, acu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
