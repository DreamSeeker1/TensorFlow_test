{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liuyanfang/anaconda3/envs/tensorflow1.4/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保存和恢复变量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    # Model parameters\n",
    "    W = tf.Variable([.3], dtype=tf.float32)\n",
    "    b = tf.Variable([-.3], dtype=tf.float32)\n",
    "    # Model input and output\n",
    "    x = tf.placeholder(tf.float32)\n",
    "    linear_model = W*x + b\n",
    "    y = tf.placeholder(tf.float32)\n",
    "    # loss\n",
    "    loss = tf.reduce_mean(tf.square(linear_model - y)) # MSE\n",
    "    # optimizer\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "    train = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义session, 存储变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W: [-0.999996] b: [0.99998856] loss: 2.2052582e-11\n",
      "Model saved in file: ./tmp/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "# training data\n",
    "x_train = [1, 2, 3, 4]\n",
    "y_train = [0, -1, -2, -3]\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    saver = tf.train.Saver()\n",
    "    # training loop\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    for i in range(5000):\n",
    "        sess.run(train, {x: x_train, y: y_train})\n",
    "    # evaluate training accuracy\n",
    "    curr_W, curr_b, curr_loss = sess.run([W, b, loss], {x: x_train, y: y_train})\n",
    "    print(\"W: %s b: %s loss: %s\"%(curr_W, curr_b, curr_loss))\n",
    "    save_path = saver.save(sess, \"./tmp/model.ckpt\")\n",
    "    print(\"Model saved in file: %s\" % save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "恢复变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./tmp/model.ckpt\n",
      "W: [-0.999996] b: [0.99998856] loss: 2.2052582e-11\n",
      "Model restored\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=graph) as sess:\n",
    "    # 定义saver\n",
    "    saver = tf.train.Saver()\n",
    "    # 恢复模型\n",
    "    saver.restore(sess, \"./tmp/model.ckpt\")\n",
    "    curr_W, curr_b, curr_loss = sess.run([W, b, loss], {x: x_train, y: y_train})\n",
    "    print(\"W: %s b: %s loss: %s\"%(curr_W, curr_b, curr_loss))\n",
    "    print(\"Model restored\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "选择要保存的变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_t = tf.Graph()\n",
    "with graph_t.as_default():\n",
    "    a = tf.Variable(1.5, name='var_a')\n",
    "    b = tf.Variable(2.5, name='var_b')\n",
    "    op = a.assign_add(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session(graph=graph_t) as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    sess.run(op)\n",
    "    saver = tf.train.Saver([a])  # 与 tf.train.Saver({var_a: a})等价\n",
    "    saver.save(sess, './tmp/model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./tmp/model.ckpt\n",
      "2.5\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=graph_t) as sess:\n",
    "    # 单独初始化b\n",
    "    sess.run(b.initializer)\n",
    "    saver = tf.train.Saver([a])  # 与 tf.train.Saver({var_a: a})等价\n",
    "    saver.restore(sess, './tmp/model.ckpt')\n",
    "    print(sess.run(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W: [-0.999996] b: [0.99998856] loss: 2.2052582e-11\n"
     ]
    }
   ],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    # Model parameters\n",
    "    W = tf.Variable([.3], dtype=tf.float32)\n",
    "    b = tf.Variable([-.3], dtype=tf.float32)\n",
    "    # Model input and output\n",
    "    x = tf.placeholder(tf.float32)\n",
    "    linear_model = W*x + b\n",
    "    y = tf.placeholder(tf.float32)\n",
    "    # loss\n",
    "    loss = tf.reduce_mean(tf.square(linear_model - y)) # MSE\n",
    "    summary_loss = tf.summary.scalar('MSE', loss)\n",
    "    summary_b = tf.summary.scalar('b', b[0])\n",
    "    # optimizer\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "    train = optimizer.minimize(loss)\n",
    "\n",
    "    \n",
    "# training data\n",
    "x_train = [1, 2, 3, 4]\n",
    "y_train = [0, -1, -2, -3]\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    # define summary writer\n",
    "    writer = tf.summary.FileWriter('./tmp/visualization/')\n",
    "    # merge summaries\n",
    "    merged = tf.summary.merge_all()\n",
    "    # training loop\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    for i in range(5000):\n",
    "        _, s_m = sess.run([train, merged], {x: x_train, y: y_train})\n",
    "        writer.add_summary(s_m, global_step=i)\n",
    "    # evaluate training accuracy\n",
    "    curr_W, curr_b, curr_loss = sess.run([W, b, loss], {x: x_train, y: y_train})\n",
    "    print(\"W: %s b: %s loss: %s\"%(curr_W, curr_b, curr_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W: [-0.999996] b: [0.99998856] loss: 2.2052582e-11\n"
     ]
    }
   ],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    # Model parameters\n",
    "    W = tf.Variable([.3], dtype=tf.float32)\n",
    "    b = tf.Variable([-.3], dtype=tf.float32)\n",
    "    # Model input and output\n",
    "    x = tf.placeholder(tf.float32)\n",
    "    linear_model = W*x + b\n",
    "    y = tf.placeholder(tf.float32)\n",
    "    # loss\n",
    "    loss = tf.reduce_mean(tf.square(linear_model - y)) # MSE\n",
    "    summary_loss = tf.summary.scalar('MSE', loss)\n",
    "    summary_b = tf.summary.scalar('b', b[0])\n",
    "    # optimizer\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "    train = optimizer.minimize(loss)\n",
    "\n",
    "    \n",
    "# training data\n",
    "x_train = [1, 2, 3, 4]\n",
    "y_train = [0, -1, -2, -3]\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    # define summary writer\n",
    "    writer = tf.summary.FileWriter('./tmp/visualization/', graph=graph)\n",
    "    # merge summaries\n",
    "    merged = tf.summary.merge_all()\n",
    "    # training loop\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    for i in range(5000):\n",
    "        _, s_m = sess.run([train, merged], {x: x_train, y: y_train})\n",
    "        writer.add_summary(s_m, global_step=i)\n",
    "    # evaluate training accuracy\n",
    "    curr_W, curr_b, curr_loss = sess.run([W, b, loss], {x: x_train, y: y_train})\n",
    "    print(\"W: %s b: %s loss: %s\"%(curr_W, curr_b, curr_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 最终代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W: [-0.999996] b: [0.99998856] loss: 2.2052582e-11\n"
     ]
    }
   ],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    # Model parameters\n",
    "    W = tf.Variable([.3], dtype=tf.float32, name='W')\n",
    "    b = tf.Variable([-.3], dtype=tf.float32, name='b')\n",
    "    # Model input and output\n",
    "    x = tf.placeholder(tf.float32, name='input_x')\n",
    "    y = tf.placeholder(tf.float32, name='input_y')\n",
    "    with tf.name_scope('linear_model'):\n",
    "        linear_model = W*x + b\n",
    "    with tf.name_scope('cal_loss'):\n",
    "        # loss\n",
    "        loss = tf.reduce_mean(tf.square(linear_model - y), name='loss') # MSE\n",
    "    with tf.name_scope('add_summary'):\n",
    "        summary_loss = tf.summary.scalar('MSE', loss)\n",
    "        summary_b = tf.summary.scalar('b', b[0])\n",
    "    with tf.name_scope('train_model'):\n",
    "        # optimizer\n",
    "        optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "        train = optimizer.minimize(loss)\n",
    "\n",
    "    \n",
    "# training data\n",
    "x_train = [1, 2, 3, 4]\n",
    "y_train = [0, -1, -2, -3]\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    # define summary writer\n",
    "    writer = tf.summary.FileWriter('./tmp/visualization/', graph=graph)\n",
    "    # merge summaries\n",
    "    merged = tf.summary.merge_all()\n",
    "    # training loop\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    for i in range(5000):\n",
    "        _, s_m = sess.run([train, merged], {x: x_train, y: y_train})\n",
    "        writer.add_summary(s_m, global_step=i)\n",
    "    # evaluate training accuracy\n",
    "    curr_W, curr_b, curr_loss = sess.run([W, b, loss], {x: x_train, y: y_train})\n",
    "    print(\"W: %s b: %s loss: %s\"%(curr_W, curr_b, curr_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 练习 ：以多项式回归的例子进行实验，增加模型保存以及可视化计算图的部分（10分钟）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "with open('./poly.pkl', 'rb') as f:\n",
    "    x, y = pickle.load(f)\n",
    "whole = np.array([x, y]).T\n",
    "train = whole[:-64]\n",
    "test = whole[-64:]\n",
    "def gen_batch(data):\n",
    "    for i in range(len(data) // 64):\n",
    "        pos = 64 * i\n",
    "        yield data[pos : pos + 64]\n",
    "lr = 0.00001\n",
    "epoch = 500\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"compute_power_of_x/concat:0\", shape=(?, 5), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    # 定义placeholder\n",
    "    x_t = tf.placeholder(shape=[None, 1], dtype=tf.float64, name='x')\n",
    "    y_t = tf.placeholder(shape=[None, 1], dtype=tf.float64, name='y')\n",
    "    \n",
    "    # 计算x的n次方\n",
    "    with tf.name_scope(\"compute_power_of_x\"):\n",
    "        x_pow = tf.concat([tf.ones(shape=tf.shape(x_t), dtype=tf.float64), \n",
    "                           x_t, tf.pow(x_t, 2), tf.pow(x_t, 3), tf.pow(x_t, 4)], axis=1)\n",
    "        print(x_pow)\n",
    "    # 定义权重\n",
    "    W = tf.Variable(tf.truncated_normal(shape=(5, 1), dtype=tf.float64), name=\"weight_matrix\")\n",
    "    # 计算多项式\n",
    "    y_pred = tf.matmul(x_pow, W)\n",
    "    with tf.name_scope(\"calculate_loss\"):\n",
    "        # 定义loss\n",
    "        loss = tf.reduce_mean(tf.pow(y_pred - y_t, 2))\n",
    "    # 使用SGD对loss进行优化\n",
    "    opt = tf.train.GradientDescentOptimizer(lr).minimize(loss)\n",
    "    tf.summary.scalar('loss', loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session(graph=graph) as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    merged = tf.summary.merge_all()\n",
    "    writer = tf.summary.FileWriter('./tmp', graph=graph)\n",
    "    saver = tf.train.Saver()\n",
    "    step= 0\n",
    "    for epoch in range(epoch):\n",
    "        for minibatch in gen_batch(train):\n",
    "            _, m = sess.run([opt, merged], \n",
    "                            feed_dict={x_t: np.reshape(minibatch[:, 0], (-1, 1)), \n",
    "                                       y_t: np.reshape(minibatch[:, 1], (-1, 1))})\n",
    "            writer.add_summary(m, global_step=step)\n",
    "            step += 1\n",
    "    print(\"Training Finished\")\n",
    "    res, l = sess.run([W, loss], \n",
    "                            feed_dict={x_t: np.reshape(test[:, 0], (-1, 1)), \n",
    "                                       y_t: np.reshape(test[:, 1], (-1, 1))})\n",
    "    print(\"Testing Loss:{:>11.4f}\".format(l))\n",
    "    saver.save(sess, './tmp/model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session(graph=graph) as sess:\n",
    "    saver.restore(sess, './tmp/model.ckpt')\n",
    "    res, l = sess.run([W, loss], \n",
    "                            feed_dict={x_t: np.reshape(test[:, 0], (-1, 1)), \n",
    "                                       y_t: np.reshape(test[:, 1], (-1, 1))})\n",
    "    print(\"Testing Loss:{:>11.4f}\".format(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
